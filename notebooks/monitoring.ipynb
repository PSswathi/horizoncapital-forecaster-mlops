{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad51fef",
   "metadata": {},
   "source": [
    "### Name: Swathi Subramanyam Pabbathi\n",
    "\n",
    "### Date: 02/07/2026\n",
    "\n",
    "\n",
    "### Assignment 5.1: ML System Observability - Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32104cc",
   "metadata": {},
   "source": [
    "### Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e353c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker SDK: 2.256.1\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.model import ModelPackage\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import StringDeserializer\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from config.config import BUCKET_NAME, S3_PREFIX, AWS_REGION, TARGET_COLUMN, MODEL_NAME\n",
    "\n",
    "print(\"SageMaker SDK:\", sagemaker.__version__)\n",
    "print(\"Region:\", AWS_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30393401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role, session, Session, image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa45edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "ROLE_ARN = os.getenv(\"SAGEMAKER_ROLE_ARN\")\n",
    "if not ROLE_ARN:\n",
    "    raise RuntimeError(\"SAGEMAKER_ROLE_ARN not found in .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02537b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sessions / clients\n",
    "boto_sess = boto3.Session(region_name=AWS_REGION)\n",
    "sm_sess = Session(boto_session=boto_sess)\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=AWS_REGION)\n",
    "s3_client = boto3.client(\"s3\", region_name=AWS_REGION)\n",
    "\n",
    "bucket = BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25dea8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded job_name: xgb-nfci-reg-2026-02-08-12-30-10\n",
      "Loaded prefix: nfci-xgboost-regression\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load latest training run metadata (so no hardcoding)\n",
    "\n",
    "prefix = \"nfci-xgboost-regression\"  # same as training notebook prefix\n",
    "metadata_key = f\"{prefix}/run_metadata/latest.json\"\n",
    "\n",
    "obj = s3_client.get_object(Bucket=bucket, Key=metadata_key)\n",
    "run_metadata = json.loads(obj[\"Body\"].read())\n",
    "\n",
    "job_name = run_metadata[\"training_job_name\"]\n",
    "training_prefix = run_metadata[\"training_prefix\"]\n",
    "\n",
    "print(\"Loaded job_name:\", job_name)\n",
    "print(\"Loaded prefix:\", training_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6256a",
   "metadata": {},
   "source": [
    "### Retrieve Latest Model from SageMaker Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aebe37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest model package ARN: arn:aws:sagemaker:us-east-1:222634372778:model-package/nfci-xgboost-group/2\n",
      "Version: 2\n",
      "Approval: Approved\n"
     ]
    }
   ],
   "source": [
    "# Get latest approved/pending model package from Model Registry\n",
    "model_package_group = f\"{MODEL_NAME}-group\"   # IMPORTANT: must match your evaluation notebook\n",
    "resp = sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group,\n",
    "    SortBy=\"CreationTime\",\n",
    "    SortOrder=\"Descending\",\n",
    "    MaxResults=1\n",
    ")\n",
    "\n",
    "pkgs = resp[\"ModelPackageSummaryList\"]\n",
    "if not pkgs:\n",
    "    raise ValueError(f\"No model packages found in group: {model_package_group}\")\n",
    "\n",
    "latest_model = pkgs[0]\n",
    "model_package_arn = latest_model[\"ModelPackageArn\"]\n",
    "\n",
    "print(\"Latest model package ARN:\", model_package_arn)\n",
    "print(\"Version:\", latest_model[\"ModelPackageVersion\"])\n",
    "print(\"Approval:\", latest_model[\"ModelApprovalStatus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aaa726",
   "metadata": {},
   "source": [
    "### Deploy Endpoint with Data Capture Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f0e8391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying endpoint: nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10\n",
      "------!Endpoint deployed: nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10\n",
      "Data capture: s3://nfci-forecasting-222634372778/nfci-xgboost-regression/data-capture/nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deploy endpoint with Data Capture enabled\n",
    "\n",
    "endpoint_name = f\"nfci-xgb-endpoint-{job_name}\"[:63]  # endpoint name max length 63\n",
    "\n",
    "data_capture_prefix = f\"{training_prefix}/data-capture/{endpoint_name}\"\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=f\"s3://{bucket}/{data_capture_prefix}\",\n",
    "    capture_options=[\"Input\", \"Output\"],\n",
    "    csv_content_types=[\"text/csv\"],\n",
    ")\n",
    "\n",
    "model = ModelPackage(\n",
    "    role=ROLE_ARN,\n",
    "    model_package_arn=model_package_arn,\n",
    "    sagemaker_session=sm_sess,\n",
    ")\n",
    "\n",
    "print(\"Deploying endpoint:\", endpoint_name)\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Endpoint deployed:\", endpoint_name)\n",
    "print(\"Data capture:\", f\"s3://{bucket}/{data_capture_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83bc6087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointStatus: InService\n",
      "Predictor ready: nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import StringDeserializer\n",
    "\n",
    "# wait for endpoint\n",
    "while True:\n",
    "    desc = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = desc[\"EndpointStatus\"]\n",
    "    print(\"EndpointStatus:\", status)\n",
    "    if status == \"InService\":\n",
    "        break\n",
    "    if status == \"Failed\":\n",
    "        raise RuntimeError(\"Endpoint deployment failed: \" + str(desc))\n",
    "    time.sleep(20)\n",
    "\n",
    "# Create predictor manually\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sm_sess\n",
    ")\n",
    "\n",
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = StringDeserializer()\n",
    "\n",
    "print(\"Predictor ready:\", predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4072490",
   "metadata": {},
   "source": [
    "### Load Production Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fefc03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Send a few inference requests (to generate capture logs)\n",
    "test_s3 = f\"s3://{bucket}/{S3_PREFIX['test']}/features.parquet\"\n",
    "df_test = pd.read_parquet(test_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "220a1140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production data shape: (2400, 80)\n",
      "Date range: 2020-01-01 00:00:00 to 2023-12-01 00:00:00\n",
      "States: 50\n",
      "\n",
      "Columns: ['state_fips', 'date', 'UNRATE', 'PAYEMS', 'CIVPART', 'EMRATIO', 'U6RATE', 'AWHMAN', 'AHETPI', 'CPIAUCSL']...\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "obj = s3_client.get_object(\n",
    "    Bucket=BUCKET_NAME,\n",
    "    Key='data/splits/production/features.parquet'\n",
    ")\n",
    "production_df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "print(f\"Production data shape: {production_df.shape}\")\n",
    "print(f\"Date range: {production_df['date'].min()} to {production_df['date'].max()}\")\n",
    "print(f\"States: {production_df['state_fips'].nunique()}\")\n",
    "print(f\"\\nColumns: {list(production_df.columns)[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5602e9",
   "metadata": {},
   "source": [
    "### Generate Sample Predictions (Trigger Data Capture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1701fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production period NFCI values: 48 months\n",
      "\n",
      "First 5 values:\n",
      "date\n",
      "2020-01-01   -0.61879\n",
      "2020-02-01   -0.29288\n",
      "2020-03-01    0.28082\n",
      "2020-04-01    0.16847\n",
      "2020-05-01   -0.26647\n",
      "Name: NFCI, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get actual NFCI values from production period\n",
    "# These are the ground truth values to compare against prediction\n",
    "actual_nfci = production_df.groupby('date')['NFCI'].first().sort_index()\n",
    "\n",
    "print(f\"Production period NFCI values: {len(actual_nfci)} months\")\n",
    "print(f\"\\nFirst 5 values:\")\n",
    "print(actual_nfci.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0377cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns like training\n",
    "df_test = df_test.drop(columns=[\"date\", \"Datetime\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb9a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate y and X\n",
    "y_true = df_test[TARGET_COLUMN].values\n",
    "X = df_test.drop(columns=[TARGET_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af419284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred raw: {\"predictions\": [{\"score\": -0.5691239833831787}]}\n",
      "pred raw: {\"predictions\": [{\"score\": -0.4638028144836426}]}\n",
      "pred raw: {\"predictions\": [{\"score\": -0.5707794427871704}]}\n",
      "pred raw: {\"predictions\": [{\"score\": -0.572127103805542}]}\n",
      "pred raw: {\"predictions\": [{\"score\": -0.5712562203407288}]}\n",
      "Waiting 60s for capture logs to land in S3...\n"
     ]
    }
   ],
   "source": [
    "# Send first 5 rows\n",
    "for i in range(5):\n",
    "    row = X.iloc[i].tolist()\n",
    "    resp = predictor.predict(row)  # CSV row\n",
    "    print(\"pred raw:\", resp)\n",
    "\n",
    "print(\"Waiting 60s for capture logs to land in S3...\")\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ea4a2",
   "metadata": {},
   "source": [
    "### Create Baseline Dataset for Model Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98ca5cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2026-02-08-18-26-45-726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline dataset uploaded: s3://sagemaker-us-east-1-222634372778/nfci-xgboost-regression/monitoring/baseline/baseline.csv\n",
      ".......................2026-02-08 18:27:54.790463: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-02-08 18:27:54.790505: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-02-08 18:27:56.500836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2026-02-08 18:27:56.500894: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-02-08 18:27:56.500922: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-2-196-57.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2026-02-08 18:27:56.501386: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-08 18:27:58,201 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:222634372778:processing-job/baseline-suggestion-job-2026-02-08-18-26-45-726', 'ProcessingJobName': 'baseline-suggestion-job-2026-02-08-18-26-45-726', 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-222634372778/nfci-xgboost-regression/monitoring/baseline/baseline.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinitionInput': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://nfci-forecasting-222634372778/nfci-xgboost-regression/monitoring/baseline-results/xgb-nfci-reg-2026-02-08-12-30-10', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.large', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'NetworkConfig': {'VpcConfig': None, 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False}, 'RoleArn': 'arn:aws:iam::222634372778:role/service-role/AmazonSageMaker-ExecutionRole-20250603T080776', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\n",
      "2026-02-08 18:27:58,202 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\n",
      "2026-02-08 18:27:58,202 - __main__ - INFO - categorical_drift_method:None\n",
      "2026-02-08 18:27:58,202 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\n",
      "2026-02-08 18:27:58,202 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\n",
      "2026-02-08 18:27:58,202 - bootstrap - INFO - Copy aws jars\n",
      "2026-02-08 18:27:58,524 - bootstrap - INFO - Copy cluster config\n",
      "2026-02-08 18:27:58,526 - bootstrap - INFO - Write runtime cluster config\n",
      "2026-02-08 18:27:58,527 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.large', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.large', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0', 'topology': None}\n",
      "2026-02-08 18:27:58,539 - bootstrap - INFO - Finished Yarn configuration files setup.\n",
      "2026-02-08 18:27:58,539 - bootstrap - INFO - Starting spark process for master node algo-1\n",
      "2026-02-08 18:27:58,539 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\n",
      "WARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\n",
      "2026-02-08 18:28:00,273 INFO namenode.NameNode: STARTUP_MSG: \n",
      "/************************************************************\n",
      "STARTUP_MSG: Starting NameNode\n",
      "STARTUP_MSG:   host = algo-1/10.2.196.57\n",
      "STARTUP_MSG:   args = [-format, -force]\n",
      "STARTUP_MSG:   version = 3.0.0\n",
      "STARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoo\n",
      "p-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar\n",
      "STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\n",
      "STARTUP_MSG:   java = 1.8.0_462\n",
      "************************************************************/\n",
      "2026-02-08 18:28:00,291 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n",
      "2026-02-08 18:28:00,305 INFO namenode.NameNode: createNameNode [-format, -force]\n",
      "Formatting using clusterid: CID-83cc93fe-e839-40cb-a5a4-ccbbba2fe7bf\n",
      "2026-02-08 18:28:01,225 INFO namenode.FSEditLog: Edit logging is async:true\n",
      "2026-02-08 18:28:01,254 INFO namenode.FSNamesystem: KeyProvider: null\n",
      "2026-02-08 18:28:01,256 INFO namenode.FSNamesystem: fsLock is fair: true\n",
      "2026-02-08 18:28:01,260 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\n",
      "2026-02-08 18:28:01,277 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\n",
      "2026-02-08 18:28:01,277 INFO namenode.FSNamesystem: supergroup          = supergroup\n",
      "2026-02-08 18:28:01,277 INFO namenode.FSNamesystem: isPermissionEnabled = true\n",
      "2026-02-08 18:28:01,277 INFO namenode.FSNamesystem: HA Enabled: false\n",
      "2026-02-08 18:28:01,369 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\n",
      "2026-02-08 18:28:01,428 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\n",
      "2026-02-08 18:28:01,428 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n",
      "2026-02-08 18:28:01,442 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\n",
      "2026-02-08 18:28:01,446 INFO blockmanagement.BlockManager: The block deletion will start around 2026 Feb 08 18:28:01\n",
      "2026-02-08 18:28:01,448 INFO util.GSet: Computing capacity for map BlocksMap\n",
      "2026-02-08 18:28:01,448 INFO util.GSet: VM type       = 64-bit\n",
      "2026-02-08 18:28:01,452 INFO util.GSet: 2.0% max memory 1.4 GB = 28.3 MB\n",
      "2026-02-08 18:28:01,453 INFO util.GSet: capacity      = 2^22 = 4194304 entries\n",
      "2026-02-08 18:28:01,500 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\n",
      "2026-02-08 18:28:01,505 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\n",
      "2026-02-08 18:28:01,506 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n",
      "2026-02-08 18:28:01,506 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\n",
      "2026-02-08 18:28:01,506 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\n",
      "2026-02-08 18:28:01,506 INFO blockmanagement.BlockManager: defaultReplication         = 3\n",
      "2026-02-08 18:28:01,506 INFO blockmanagement.BlockManager: maxReplication             = 512\n",
      "2026-02-08 18:28:01,506 INFO blockmanagement.BlockManager: minReplication             = 1\n",
      "2026-02-08 18:28:01,506 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n",
      "2026-02-08 18:28:01,506 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\n",
      "2026-02-08 18:28:01,507 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n",
      "2026-02-08 18:28:01,507 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n",
      "2026-02-08 18:28:01,587 INFO util.GSet: Computing capacity for map INodeMap\n",
      "2026-02-08 18:28:01,587 INFO util.GSet: VM type       = 64-bit\n",
      "2026-02-08 18:28:01,587 INFO util.GSet: 1.0% max memory 1.4 GB = 14.2 MB\n",
      "2026-02-08 18:28:01,588 INFO util.GSet: capacity      = 2^21 = 2097152 entries\n",
      "2026-02-08 18:28:01,589 INFO namenode.FSDirectory: ACLs enabled? false\n",
      "2026-02-08 18:28:01,589 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\n",
      "2026-02-08 18:28:01,589 INFO namenode.FSDirectory: XAttrs enabled? true\n",
      "2026-02-08 18:28:01,590 INFO namenode.NameNode: Caching file names occurring more than 10 times\n",
      "2026-02-08 18:28:01,595 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\n",
      "2026-02-08 18:28:01,599 INFO util.GSet: Computing capacity for map cachedBlocks\n",
      "2026-02-08 18:28:01,600 INFO util.GSet: VM type       = 64-bit\n",
      "2026-02-08 18:28:01,600 INFO util.GSet: 0.25% max memory 1.4 GB = 3.5 MB\n",
      "2026-02-08 18:28:01,600 INFO util.GSet: capacity      = 2^19 = 524288 entries\n",
      "2026-02-08 18:28:01,610 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\n",
      "2026-02-08 18:28:01,610 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\n",
      "2026-02-08 18:28:01,611 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\n",
      "2026-02-08 18:28:01,615 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n",
      "2026-02-08 18:28:01,615 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n",
      "2026-02-08 18:28:01,618 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n",
      "2026-02-08 18:28:01,619 INFO util.GSet: VM type       = 64-bit\n",
      "2026-02-08 18:28:01,619 INFO util.GSet: 0.029999999329447746% max memory 1.4 GB = 434.8 KB\n",
      "2026-02-08 18:28:01,619 INFO util.GSet: capacity      = 2^16 = 65536 entries\n",
      "2026-02-08 18:28:01,651 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1084732536-10.2.196.57-1770575281641\n",
      "2026-02-08 18:28:01,673 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\n",
      "2026-02-08 18:28:01,687 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\n",
      "2026-02-08 18:28:01,803 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\n",
      "2026-02-08 18:28:01,824 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n",
      "2026-02-08 18:28:01,831 INFO namenode.NameNode: SHUTDOWN_MSG: \n",
      "/************************************************************\n",
      "SHUTDOWN_MSG: Shutting down NameNode at algo-1/10.2.196.57\n",
      "************************************************************/\n",
      "2026-02-08 18:28:01,842 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\n",
      "2026-02-08 18:28:03,922 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\n",
      "2026-02-08 18:28:03,922 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\n",
      "2026-02-08 18:28:06,066 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\n",
      "2026-02-08 18:28:06,066 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "WARNING: /var/log/yarn/ does not exist. Creating.\n",
      "2026-02-08 18:28:08,624 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\n",
      "2026-02-08 18:28:08,624 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "2026-02-08 18:28:10,934 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\n",
      "2026-02-08 18:28:10,941 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "2026-02-08 18:28:13,489 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\n",
      "2026-02-08 18:28:13,489 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\n",
      "2026-02-08 18:28:23,497 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\n",
      "2026-02-08 18:28:26,705 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2026-02-08 18:28:27,483 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\n",
      "2026-02-08 18:28:27,530 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\n",
      "2026-02-08 18:28:27,558 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\n",
      "2026-02-08 18:28:28,426 INFO spark.SparkContext: Running Spark version 3.3.0\n",
      "2026-02-08 18:28:28,461 INFO resource.ResourceUtils: ==============================================================\n",
      "2026-02-08 18:28:28,462 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\n",
      "2026-02-08 18:28:28,462 INFO resource.ResourceUtils: ==============================================================\n",
      "2026-02-08 18:28:28,463 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\n",
      "2026-02-08 18:28:28,501 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 5673, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "2026-02-08 18:28:28,517 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor\n",
      "2026-02-08 18:28:28,519 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\n",
      "2026-02-08 18:28:28,610 INFO spark.SecurityManager: Changing view acls to: root\n",
      "2026-02-08 18:28:28,611 INFO spark.SecurityManager: Changing modify acls to: root\n",
      "2026-02-08 18:28:28,611 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "2026-02-08 18:28:28,612 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "2026-02-08 18:28:28,612 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2026-02-08 18:28:29,178 INFO util.Utils: Successfully started service 'sparkDriver' on port 32947.\n",
      "2026-02-08 18:28:29,257 INFO spark.SparkEnv: Registering MapOutputTracker\n",
      "2026-02-08 18:28:29,320 INFO spark.SparkEnv: Registering BlockManagerMaster\n",
      "2026-02-08 18:28:29,366 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "2026-02-08 18:28:29,367 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "2026-02-08 18:28:29,418 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "2026-02-08 18:28:29,479 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-89f47501-05a0-408a-bfcf-b961bd413f30\n",
      "2026-02-08 18:28:29,504 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\n",
      "2026-02-08 18:28:29,564 INFO spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "2026-02-08 18:28:29,612 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.2.196.57:32947/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1770575308418\n",
      "2026-02-08 18:28:30,385 INFO client.RMProxy: Connecting to ResourceManager at /10.2.196.57:8032\n",
      "2026-02-08 18:28:31,266 INFO conf.Configuration: resource-types.xml not found\n",
      "2026-02-08 18:28:31,267 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2026-02-08 18:28:31,275 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (7736 MB per container)\n",
      "2026-02-08 18:28:31,276 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\n",
      "2026-02-08 18:28:31,276 INFO yarn.Client: Setting up container launch context for our AM\n",
      "2026-02-08 18:28:31,276 INFO yarn.Client: Setting up the launch environment for our AM container\n",
      "2026-02-08 18:28:31,284 INFO yarn.Client: Preparing resources for our AM container\n",
      "2026-02-08 18:28:31,398 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "2026-02-08 18:28:34,023 INFO yarn.Client: Uploading resource file:/tmp/spark-cd6d6782-5e76-4e66-b043-055b4222ab76/__spark_libs__8137967265565657468.zip -> hdfs://10.2.196.57/user/root/.sparkStaging/application_1770575290417_0001/__spark_libs__8137967265565657468.zip\n",
      "2026-02-08 18:28:36,446 INFO yarn.Client: Uploading resource file:/tmp/spark-cd6d6782-5e76-4e66-b043-055b4222ab76/__spark_conf__3657595756862997628.zip -> hdfs://10.2.196.57/user/root/.sparkStaging/application_1770575290417_0001/__spark_conf__.zip\n",
      "2026-02-08 18:28:36,513 INFO spark.SecurityManager: Changing view acls to: root\n",
      "2026-02-08 18:28:36,514 INFO spark.SecurityManager: Changing modify acls to: root\n",
      "2026-02-08 18:28:36,515 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "2026-02-08 18:28:36,515 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "2026-02-08 18:28:36,517 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2026-02-08 18:28:36,560 INFO yarn.Client: Submitting application application_1770575290417_0001 to ResourceManager\n",
      "2026-02-08 18:28:36,861 INFO impl.YarnClientImpl: Submitted application application_1770575290417_0001\n",
      "2026-02-08 18:28:37,866 INFO yarn.Client: Application report for application_1770575290417_0001 (state: ACCEPTED)\n",
      "2026-02-08 18:28:37,871 INFO yarn.Client: \n",
      "#011 client token: N/A\n",
      "#011 diagnostics: [Sun Feb 08 18:28:37 +0000 2026] Scheduler has assigned a container for AM, waiting for AM container to be launched\n",
      "#011 ApplicationMaster host: N/A\n",
      "#011 ApplicationMaster RPC port: -1\n",
      "#011 queue: default\n",
      "#011 start time: 1770575316716\n",
      "#011 final status: UNDEFINED\n",
      "#011 tracking URL: http://algo-1:8088/proxy/application_1770575290417_0001/\n",
      "#011 user: root\n",
      "2026-02-08 18:28:38,874 INFO yarn.Client: Application report for application_1770575290417_0001 (state: ACCEPTED)\n",
      "2026-02-08 18:28:39,885 INFO yarn.Client: Application report for application_1770575290417_0001 (state: ACCEPTED)\n",
      "2026-02-08 18:28:40,892 INFO yarn.Client: Application report for application_1770575290417_0001 (state: ACCEPTED)\n",
      "2026-02-08 18:28:41,897 INFO yarn.Client: Application report for application_1770575290417_0001 (state: ACCEPTED)\n",
      "2026-02-08 18:28:42,901 INFO yarn.Client: Application report for application_1770575290417_0001 (state: ACCEPTED)\n",
      "2026-02-08 18:28:43,905 INFO yarn.Client: Application report for application_1770575290417_0001 (state: ACCEPTED)\n",
      "2026-02-08 18:28:44,909 INFO yarn.Client: Application report for application_1770575290417_0001 (state: ACCEPTED)\n",
      "2026-02-08 18:28:45,894 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1770575290417_0001), /proxy/application_1770575290417_0001\n",
      "2026-02-08 18:28:45,915 INFO yarn.Client: Application report for application_1770575290417_0001 (state: RUNNING)\n",
      "2026-02-08 18:28:45,916 INFO yarn.Client: \n",
      "#011 client token: N/A\n",
      "#011 diagnostics: N/A\n",
      "#011 ApplicationMaster host: 10.2.196.57\n",
      "#011 ApplicationMaster RPC port: -1\n",
      "#011 queue: default\n",
      "#011 start time: 1770575316716\n",
      "#011 final status: UNDEFINED\n",
      "#011 tracking URL: http://algo-1:8088/proxy/application_1770575290417_0001/\n",
      "#011 user: root\n",
      "2026-02-08 18:28:45,918 INFO cluster.YarnClientSchedulerBackend: Application application_1770575290417_0001 has started running.\n",
      "2026-02-08 18:28:45,957 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46029.\n",
      "2026-02-08 18:28:45,958 INFO netty.NettyBlockTransferService: Server created on 10.2.196.57:46029\n",
      "2026-02-08 18:28:45,961 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "2026-02-08 18:28:45,996 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.2.196.57, 46029, None)\n",
      "2026-02-08 18:28:46,005 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.2.196.57:46029 with 1458.6 MiB RAM, BlockManagerId(driver, 10.2.196.57, 46029, None)\n",
      "2026-02-08 18:28:46,009 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.2.196.57, 46029, None)\n",
      "2026-02-08 18:28:46,012 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.2.196.57, 46029, None)\n",
      "2026-02-08 18:28:46,202 INFO util.log: Logging initialized @22046ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "2026-02-08 18:28:48,469 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\n",
      "2026-02-08 18:28:54,940 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.2.196.57:55566) with ID 1,  ResourceProfileId 0\n",
      "2026-02-08 18:28:55,419 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:39391 with 2.8 GiB RAM, BlockManagerId(1, algo-1, 39391, None)\n",
      "2026-02-08 18:29:00,252 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\n",
      "2026-02-08 18:29:00,635 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\n",
      "2026-02-08 18:29:00,752 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "2026-02-08 18:29:00,762 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\n",
      "2026-02-08 18:29:02,981 INFO datasources.InMemoryFileIndex: It took 108 ms to list leaf files for 1 paths.\n",
      "2026-02-08 18:29:03,373 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\n",
      "2026-02-08 18:29:03,928 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1458.2 MiB)\n",
      "2026-02-08 18:29:03,932 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.2.196.57:46029 (size: 39.2 KiB, free: 1458.6 MiB)\n",
      "2026-02-08 18:29:03,945 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\n",
      "2026-02-08 18:29:04,563 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2026-02-08 18:29:04,572 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2026-02-08 18:29:04,581 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0\n",
      "2026-02-08 18:29:04,711 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\n",
      "2026-02-08 18:29:04,734 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\n",
      "2026-02-08 18:29:04,735 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\n",
      "2026-02-08 18:29:04,737 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:04,739 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:04,749 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\n",
      "2026-02-08 18:29:04,856 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\n",
      "2026-02-08 18:29:04,862 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\n",
      "2026-02-08 18:29:04,863 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.2.196.57:46029 (size: 4.2 KiB, free: 1458.6 MiB)\n",
      "2026-02-08 18:29:04,864 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:04,886 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:04,888 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:04,945 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4621 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:05,329 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:39391 (size: 4.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:06,689 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:39391 (size: 39.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:07,204 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2277 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:07,208 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:07,221 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 2.425 s\n",
      "2026-02-08 18:29:07,226 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:07,227 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\n",
      "2026-02-08 18:29:07,231 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 2.518884 s\n",
      "2026-02-08 18:29:07,536 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:39391 in memory (size: 4.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:07,551 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.2.196.57:46029 in memory (size: 4.2 KiB, free: 1458.6 MiB)\n",
      "2026-02-08 18:29:11,142 INFO datasources.FileSourceStrategy: Pushed Filters: \n",
      "2026-02-08 18:29:11,144 INFO datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "2026-02-08 18:29:11,149 INFO datasources.FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 76 more fields>\n",
      "2026-02-08 18:29:11,207 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "2026-02-08 18:29:11,473 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1457.7 MiB)\n",
      "2026-02-08 18:29:11,493 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1457.7 MiB)\n",
      "2026-02-08 18:29:11,496 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.2.196.57:46029 (size: 39.1 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:11,500 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\n",
      "2026-02-08 18:29:11,520 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4583683 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "2026-02-08 18:29:11,593 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\n",
      "2026-02-08 18:29:11,595 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\n",
      "2026-02-08 18:29:11,596 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\n",
      "2026-02-08 18:29:11,596 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:11,599 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:11,601 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\n",
      "2026-02-08 18:29:11,681 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 31.0 KiB, free 1457.7 MiB)\n",
      "2026-02-08 18:29:11,684 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 1457.7 MiB)\n",
      "2026-02-08 18:29:11,685 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.2.196.57:46029 (size: 11.5 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:11,689 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:11,697 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:11,697 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:11,702 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:11,780 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:39391 (size: 11.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:14,263 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:39391 (size: 39.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:15,435 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:39391 (size: 1220.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:15,692 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3994 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:15,694 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 4.090 s\n",
      "2026-02-08 18:29:15,695 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:15,695 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:15,696 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\n",
      "2026-02-08 18:29:15,696 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 4.102293 s\n",
      "2026-02-08 18:29:16,404 INFO codegen.CodeGenerator: Code generated in 573.611822 ms\n",
      "2026-02-08 18:29:17,920 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\n",
      "2026-02-08 18:29:17,925 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:17,925 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:17,926 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:17,928 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:17,932 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:17,969 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 126.8 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:17,973 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:17,974 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.2.196.57:46029 (size: 37.8 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:17,976 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:17,980 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:17,980 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:17,991 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:18,044 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:39391 (size: 37.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:19,875 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1886 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:19,878 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.943 s\n",
      "2026-02-08 18:29:19,879 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:19,880 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:19,880 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:19,881 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:19,882 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:20,098 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:20,101 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:20,102 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:20,102 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\n",
      "2026-02-08 18:29:20,103 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:20,104 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:20,160 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 179.2 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:20,178 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:20,179 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.2.196.57:46029 (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:20,181 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:20,182 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:20,182 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:20,186 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:20,233 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:39391 (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:20,379 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:21,118 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 933 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:21,119 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.985 s\n",
      "2026-02-08 18:29:21,120 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:21,122 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:21,122 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\n",
      "2026-02-08 18:29:21,124 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 1.025322 s\n",
      "2026-02-08 18:29:21,204 INFO codegen.CodeGenerator: Code generated in 72.194123 ms\n",
      "2026-02-08 18:29:21,703 INFO codegen.CodeGenerator: Code generated in 67.120608 ms\n",
      "2026-02-08 18:29:21,806 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:39391 in memory (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:21,820 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.2.196.57:46029 in memory (size: 49.3 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:21,839 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:39391 in memory (size: 37.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:21,843 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.2.196.57:46029 in memory (size: 37.8 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:21,902 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.2.196.57:46029 in memory (size: 11.5 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:21,905 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:21,906 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:39391 in memory (size: 11.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:21,906 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:21,907 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:21,907 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:21,908 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:21,924 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:21,972 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 50.5 KiB, free 1457.7 MiB)\n",
      "2026-02-08 18:29:21,975 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:21,976 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.2.196.57:46029 (size: 19.9 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:21,977 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:21,978 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:21,978 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:21,980 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:22,008 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:39391 (size: 19.9 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:22,935 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 956 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:22,936 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 1.011 s\n",
      "2026-02-08 18:29:22,938 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:22,940 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:22,940 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\n",
      "2026-02-08 18:29:22,941 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 1.035484 s\n",
      "2026-02-08 18:29:23,907 INFO codegen.CodeGenerator: Code generated in 125.764063 ms\n",
      "2026-02-08 18:29:23,916 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\n",
      "2026-02-08 18:29:23,916 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:23,917 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:23,917 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:23,918 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:23,920 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:23,938 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 87.2 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:23,946 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:23,947 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.2.196.57:46029 (size: 27.2 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:23,948 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:23,949 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:23,949 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:23,951 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:23,966 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:39391 (size: 27.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:24,186 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 235 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:24,186 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:24,191 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.257 s\n",
      "2026-02-08 18:29:24,191 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:24,191 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:24,191 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:24,191 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:24,609 INFO codegen.CodeGenerator: Code generated in 206.095808 ms\n",
      "2026-02-08 18:29:24,626 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:24,628 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:24,628 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:24,629 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\n",
      "2026-02-08 18:29:24,629 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:24,630 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:24,633 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.8 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:24,635 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:24,642 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.2.196.57:46029 (size: 19.7 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:24,643 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:24,643 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:24,643 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:24,646 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:24,660 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:39391 (size: 19.7 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:24,666 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:24,835 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 189 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:24,836 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:24,836 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.205 s\n",
      "2026-02-08 18:29:24,837 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:24,837 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\n",
      "2026-02-08 18:29:24,837 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.211078 s\n",
      "2026-02-08 18:29:24,968 INFO codegen.CodeGenerator: Code generated in 103.510721 ms\n",
      "2026-02-08 18:29:25,308 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:25,326 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\n",
      "2026-02-08 18:29:25,326 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:25,327 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:25,327 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\n",
      "2026-02-08 18:29:25,327 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\n",
      "2026-02-08 18:29:25,331 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:25,357 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 42.9 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:25,364 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:25,365 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:25,366 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:25,366 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:25,366 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:25,368 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:25,382 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:27,161 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1793 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:27,162 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:27,163 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.830 s\n",
      "2026-02-08 18:29:27,164 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:27,164 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:27,165 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\n",
      "2026-02-08 18:29:27,165 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:27,166 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:27,168 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:27,174 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:27,175 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:27,176 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:27,177 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:27,177 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:27,181 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:27,206 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:27,215 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:27,281 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 102 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:27,282 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:27,283 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.117 s\n",
      "2026-02-08 18:29:27,283 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:27,283 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\n",
      "2026-02-08 18:29:27,284 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 1.972060 s\n",
      "2026-02-08 18:29:27,577 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\n",
      "2026-02-08 18:29:27,577 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:27,577 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:27,578 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:27,578 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:27,579 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:27,590 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 95.7 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:27,593 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:27,594 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:27,597 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:27,598 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:27,598 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:27,602 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:27,644 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:28,089 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 488 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:28,090 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:28,091 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.509 s\n",
      "2026-02-08 18:29:28,092 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:28,092 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:28,092 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:28,092 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:28,230 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:28,233 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:28,233 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:28,233 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\n",
      "2026-02-08 18:29:28,233 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:28,241 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:28,263 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 180.3 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:28,268 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:28,270 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.2.196.57:46029 (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:28,272 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:28,275 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:28,276 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:28,278 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:28,334 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:39391 (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:28,375 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:28,657 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 379 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:28,658 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:28,658 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.408 s\n",
      "2026-02-08 18:29:28,663 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:28,663 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\n",
      "2026-02-08 18:29:28,664 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.433291 s\n",
      "2026-02-08 18:29:28,922 INFO codegen.CodeGenerator: Code generated in 21.95283 ms\n",
      "2026-02-08 18:29:28,961 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:28,964 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:28,965 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:28,965 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:28,966 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:28,969 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:28,983 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 50.5 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:28,985 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:28,989 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:28,995 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:28,996 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:28,996 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:28,998 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:29,013 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:29,446 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 449 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:29,451 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 0.479 s\n",
      "2026-02-08 18:29:29,452 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:29,459 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:29,460 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\n",
      "2026-02-08 18:29:29,460 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 0.498472 s\n",
      "2026-02-08 18:29:29,564 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:29,567 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:29,601 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.2.196.57:46029 in memory (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:29,610 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:39391 in memory (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:29,712 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:29,754 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:29,798 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:29,809 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:29,845 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.2.196.57:46029 in memory (size: 19.7 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:29,861 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:39391 in memory (size: 19.7 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:29,916 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.2.196.57:46029 in memory (size: 19.9 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:29,919 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:39391 in memory (size: 19.9 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:29,939 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:29,941 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:30,004 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.2.196.57:46029 in memory (size: 27.2 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:30,005 INFO codegen.CodeGenerator: Code generated in 152.475667 ms\n",
      "2026-02-08 18:29:30,006 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:39391 in memory (size: 27.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:30,019 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\n",
      "2026-02-08 18:29:30,019 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:30,020 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:30,020 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:30,021 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:30,021 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:30,026 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 86.4 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:30,029 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:30,029 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:30,030 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:30,032 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:30,033 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:30,034 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:30,054 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:30,169 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 135 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:30,172 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:30,173 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.151 s\n",
      "2026-02-08 18:29:30,173 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:30,174 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:30,174 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:30,174 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:30,369 INFO codegen.CodeGenerator: Code generated in 104.470339 ms\n",
      "2026-02-08 18:29:30,382 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:30,383 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:30,384 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:30,384 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\n",
      "2026-02-08 18:29:30,385 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:30,385 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:30,390 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:30,392 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:30,393 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.2.196.57:46029 (size: 19.2 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:30,394 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:30,394 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:30,394 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:30,396 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:30,414 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:39391 (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:30,419 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:30,574 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 178 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:30,574 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:30,575 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.187 s\n",
      "2026-02-08 18:29:30,581 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:30,581 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\n",
      "2026-02-08 18:29:30,582 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.199770 s\n",
      "2026-02-08 18:29:30,739 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:30,742 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\n",
      "2026-02-08 18:29:30,743 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:30,743 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:30,743 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\n",
      "2026-02-08 18:29:30,744 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\n",
      "2026-02-08 18:29:30,747 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:30,761 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 42.9 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:30,765 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:30,769 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:30,770 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:30,770 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:30,772 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:30,775 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:30,787 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:30,888 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 113 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:30,889 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:30,890 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.142 s\n",
      "2026-02-08 18:29:30,892 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:30,893 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:30,893 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\n",
      "2026-02-08 18:29:30,893 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:30,894 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:30,898 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:30,906 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:30,907 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:30,909 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:30,910 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:30,910 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:30,912 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:30,934 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:30,943 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:30,991 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 79 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:30,993 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:30,993 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.097 s\n",
      "2026-02-08 18:29:30,994 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:30,994 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\n",
      "2026-02-08 18:29:30,995 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.255336 s\n",
      "2026-02-08 18:29:31,317 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\n",
      "2026-02-08 18:29:31,318 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:31,319 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:31,319 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:31,320 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:31,320 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:31,326 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 95.7 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:31,329 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:31,330 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:31,331 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:31,332 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:31,332 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:31,334 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:31,356 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:31,684 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 350 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:31,685 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:31,686 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.364 s\n",
      "2026-02-08 18:29:31,687 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:31,688 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:31,688 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:31,688 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:31,776 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:31,782 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:31,782 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:31,783 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\n",
      "2026-02-08 18:29:31,784 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:31,784 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:31,796 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 180.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:31,799 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 49.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:31,800 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.2.196.57:46029 (size: 49.4 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:31,801 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:31,802 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:31,803 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:31,804 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:31,822 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:39391 (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:31,850 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:32,242 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 438 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:32,245 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:32,249 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.464 s\n",
      "2026-02-08 18:29:32,250 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:32,250 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\n",
      "2026-02-08 18:29:32,256 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.478944 s\n",
      "2026-02-08 18:29:32,689 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:32,691 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:32,691 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:32,692 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:32,692 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:32,693 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:32,702 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 50.5 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:32,704 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:32,705 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:32,706 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:32,707 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:32,707 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:32,708 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:32,735 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:32,911 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 203 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:32,912 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.217 s\n",
      "2026-02-08 18:29:32,913 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:32,913 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:32,913 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\n",
      "2026-02-08 18:29:32,914 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.224152 s\n",
      "2026-02-08 18:29:33,243 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\n",
      "2026-02-08 18:29:33,244 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:33,244 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:33,244 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:33,245 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:33,246 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:33,257 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,263 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 86.4 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:33,265 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:33,266 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:33,266 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:33,269 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:33,270 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:33,271 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:33,273 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:33,286 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,339 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.2.196.57:46029 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:33,347 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:39391 in memory (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,357 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 86 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:33,360 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:33,360 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.112 s\n",
      "2026-02-08 18:29:33,361 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:33,362 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:33,362 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:33,362 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:33,376 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,385 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:33,449 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:33,451 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:33,453 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:33,453 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\n",
      "2026-02-08 18:29:33,453 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:33,454 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:33,452 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:33,455 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,458 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 66.2 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:33,460 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:33,462 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.2.196.57:46029 (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:33,463 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:33,464 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:33,464 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:33,470 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:33,478 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:33,484 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,487 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:39391 (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,499 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:33,509 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 40 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:33,509 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:33,510 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.053 s\n",
      "2026-02-08 18:29:33,511 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:33,512 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\n",
      "2026-02-08 18:29:33,512 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.062723 s\n",
      "2026-02-08 18:29:33,536 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:39391 in memory (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,538 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.2.196.57:46029 in memory (size: 49.4 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:33,591 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,592 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:33,646 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:33,647 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\n",
      "2026-02-08 18:29:33,648 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:33,648 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:33,648 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\n",
      "2026-02-08 18:29:33,648 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\n",
      "2026-02-08 18:29:33,652 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:33,659 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 42.9 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:33,664 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:33,665 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:33,666 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:33,666 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:33,668 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:33,672 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:33,685 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,788 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 116 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:33,788 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:33,791 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.138 s\n",
      "2026-02-08 18:29:33,793 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:33,793 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:33,793 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\n",
      "2026-02-08 18:29:33,793 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:33,794 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:33,800 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:33,803 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:33,804 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:33,804 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:33,805 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:33,805 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:33,808 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:33,819 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:33,827 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:33,854 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 46 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:33,854 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:33,855 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.056 s\n",
      "2026-02-08 18:29:33,860 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:33,860 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\n",
      "2026-02-08 18:29:33,860 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.213982 s\n",
      "2026-02-08 18:29:34,098 INFO scheduler.DAGScheduler: Registering RDD 121 (collect at AnalysisRunner.scala:326) as input to shuffle 9\n",
      "2026-02-08 18:29:34,099 INFO scheduler.DAGScheduler: Got map stage job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:34,099 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:34,100 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:34,100 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:34,101 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:34,106 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 95.7 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:34,108 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:34,109 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:34,109 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:34,110 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:34,110 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:34,112 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:34,133 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:34,385 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 274 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:34,385 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:34,386 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326) finished in 0.284 s\n",
      "2026-02-08 18:29:34,387 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:34,387 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:34,387 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:34,388 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:34,430 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:34,432 INFO scheduler.DAGScheduler: Got job 21 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:34,432 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:34,432 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\n",
      "2026-02-08 18:29:34,432 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:34,433 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:34,438 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 180.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:34,440 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 49.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:34,441 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.2.196.57:46029 (size: 49.4 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:34,443 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:34,444 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:34,444 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:34,446 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:34,457 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:39391 (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:34,474 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:34,582 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 136 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:34,583 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:34,583 INFO scheduler.DAGScheduler: ResultStage 31 (collect at AnalysisRunner.scala:326) finished in 0.149 s\n",
      "2026-02-08 18:29:34,584 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:34,584 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\n",
      "2026-02-08 18:29:34,584 INFO scheduler.DAGScheduler: Job 21 finished: collect at AnalysisRunner.scala:326, took 0.153305 s\n",
      "2026-02-08 18:29:34,716 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:34,717 INFO scheduler.DAGScheduler: Got job 22 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:34,718 INFO scheduler.DAGScheduler: Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:34,718 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:34,719 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:34,719 INFO scheduler.DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:34,729 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 50.5 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:34,731 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:34,732 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:34,733 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:34,733 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:34,733 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:34,735 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:34,750 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:34,936 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 201 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:34,936 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:34,937 INFO scheduler.DAGScheduler: ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 0.216 s\n",
      "2026-02-08 18:29:34,938 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:34,939 INFO cluster.YarnScheduler: Killing all running tasks in stage 32: Stage finished\n",
      "2026-02-08 18:29:34,939 INFO scheduler.DAGScheduler: Job 22 finished: treeReduce at KLLRunner.scala:107, took 0.222431 s\n",
      "2026-02-08 18:29:35,101 INFO scheduler.DAGScheduler: Registering RDD 139 (collect at AnalysisRunner.scala:326) as input to shuffle 10\n",
      "2026-02-08 18:29:35,101 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:35,101 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:35,101 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:35,102 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:35,102 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:35,108 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 86.4 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:35,110 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:35,116 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:35,117 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:35,117 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:35,118 INFO cluster.YarnScheduler: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:35,119 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:35,132 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:35,186 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 67 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:35,186 INFO cluster.YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:35,187 INFO scheduler.DAGScheduler: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326) finished in 0.083 s\n",
      "2026-02-08 18:29:35,188 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:35,188 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:35,188 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:35,188 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:35,268 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:35,270 INFO scheduler.DAGScheduler: Got job 24 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:35,270 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:35,270 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\n",
      "2026-02-08 18:29:35,271 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:35,273 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:35,275 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 66.2 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:35,278 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:35,278 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.2.196.57:46029 (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:35,280 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:35,280 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:35,280 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:35,282 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:35,304 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:39391 (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:35,311 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:35,324 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 42 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:35,325 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:35,325 INFO scheduler.DAGScheduler: ResultStage 35 (collect at AnalysisRunner.scala:326) finished in 0.051 s\n",
      "2026-02-08 18:29:35,327 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:35,327 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\n",
      "2026-02-08 18:29:35,328 INFO scheduler.DAGScheduler: Job 24 finished: collect at AnalysisRunner.scala:326, took 0.058537 s\n",
      "2026-02-08 18:29:35,403 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:35,406 INFO scheduler.DAGScheduler: Registering RDD 150 (countByKey at ColumnProfiler.scala:592) as input to shuffle 11\n",
      "2026-02-08 18:29:35,406 INFO scheduler.DAGScheduler: Got job 25 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:35,406 INFO scheduler.DAGScheduler: Final stage: ResultStage 37 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:35,407 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)\n",
      "2026-02-08 18:29:35,407 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 36)\n",
      "2026-02-08 18:29:35,408 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:35,419 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 42.9 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:35,422 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:35,422 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:35,423 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:35,424 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:35,424 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:35,426 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:35,438 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:35,545 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 120 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:35,545 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:35,546 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (countByKey at ColumnProfiler.scala:592) finished in 0.137 s\n",
      "2026-02-08 18:29:35,546 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:35,546 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:35,546 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 37)\n",
      "2026-02-08 18:29:35,546 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:35,547 INFO scheduler.DAGScheduler: Submitting ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:35,549 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 5.1 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:35,552 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:35,552 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:35,553 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:35,553 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:35,554 INFO cluster.YarnScheduler: Adding task set 37.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:35,555 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:35,573 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:35,577 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:35,603 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 48 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:35,604 INFO cluster.YarnScheduler: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:35,604 INFO scheduler.DAGScheduler: ResultStage 37 (countByKey at ColumnProfiler.scala:592) finished in 0.056 s\n",
      "2026-02-08 18:29:35,606 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:35,606 INFO cluster.YarnScheduler: Killing all running tasks in stage 37: Stage finished\n",
      "2026-02-08 18:29:35,607 INFO scheduler.DAGScheduler: Job 25 finished: countByKey at ColumnProfiler.scala:592, took 0.202869 s\n",
      "2026-02-08 18:29:35,735 INFO scheduler.DAGScheduler: Registering RDD 156 (collect at AnalysisRunner.scala:326) as input to shuffle 12\n",
      "2026-02-08 18:29:35,735 INFO scheduler.DAGScheduler: Got map stage job 26 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:35,736 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:35,736 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:35,736 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:35,737 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:35,744 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 95.7 KiB, free 1456.7 MiB)\n",
      "2026-02-08 18:29:35,747 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:35,747 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:35,748 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:35,748 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:35,749 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:35,752 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 30) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:35,762 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:35,978 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 30) in 227 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:35,981 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:35,982 INFO scheduler.DAGScheduler: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326) finished in 0.243 s\n",
      "2026-02-08 18:29:35,983 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:35,984 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:35,984 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:35,984 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:36,048 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:36,049 INFO scheduler.DAGScheduler: Got job 27 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:36,049 INFO scheduler.DAGScheduler: Final stage: ResultStage 40 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:36,049 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\n",
      "2026-02-08 18:29:36,050 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:36,050 INFO scheduler.DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:36,063 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 180.4 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:36,068 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 49.4 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:36,069 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.2.196.57:46029 (size: 49.4 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:36,070 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:36,075 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:36,075 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:36,077 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 31) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:36,089 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:39391 (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,104 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:36,201 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 31) in 124 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:36,201 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:36,202 INFO scheduler.DAGScheduler: ResultStage 40 (collect at AnalysisRunner.scala:326) finished in 0.148 s\n",
      "2026-02-08 18:29:36,204 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:36,204 INFO cluster.YarnScheduler: Killing all running tasks in stage 40: Stage finished\n",
      "2026-02-08 18:29:36,204 INFO scheduler.DAGScheduler: Job 27 finished: collect at AnalysisRunner.scala:326, took 0.155951 s\n",
      "2026-02-08 18:29:36,395 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:36,408 INFO scheduler.DAGScheduler: Got job 28 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:36,409 INFO scheduler.DAGScheduler: Final stage: ResultStage 41 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:36,409 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,410 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:36,411 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:36,412 INFO scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:36,418 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:36,434 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 50.5 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:36,438 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:36,439 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:36,440 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:36,440 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:36,441 INFO cluster.YarnScheduler: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:36,442 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 32) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:36,448 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,453 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,481 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:36,503 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:36,506 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,541 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:36,547 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,580 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,582 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:36,606 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.2.196.57:46029 in memory (size: 49.4 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:36,609 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:39391 in memory (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,633 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:36,647 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,652 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:36,654 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,664 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.2.196.57:46029 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:36,666 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:39391 in memory (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,672 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:36,675 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,680 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.2.196.57:46029 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:36,683 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 32) in 241 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:36,683 INFO cluster.YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:36,684 INFO scheduler.DAGScheduler: ResultStage 41 (treeReduce at KLLRunner.scala:107) finished in 0.270 s\n",
      "2026-02-08 18:29:36,685 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:36,685 INFO cluster.YarnScheduler: Killing all running tasks in stage 41: Stage finished\n",
      "2026-02-08 18:29:36,686 INFO scheduler.DAGScheduler: Job 28 finished: treeReduce at KLLRunner.scala:107, took 0.278463 s\n",
      "2026-02-08 18:29:36,698 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:39391 in memory (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,700 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:36,706 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,710 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.2.196.57:46029 in memory (size: 49.4 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:36,726 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on algo-1:39391 in memory (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,906 INFO scheduler.DAGScheduler: Registering RDD 174 (collect at AnalysisRunner.scala:326) as input to shuffle 13\n",
      "2026-02-08 18:29:36,907 INFO scheduler.DAGScheduler: Got map stage job 29 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:36,907 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:36,907 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:36,908 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:36,908 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:36,913 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 86.4 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:36,917 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:36,918 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:36,919 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:36,919 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:36,920 INFO cluster.YarnScheduler: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:36,921 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 33) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:36,935 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:36,999 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 33) in 78 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:36,999 INFO cluster.YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:37,000 INFO scheduler.DAGScheduler: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326) finished in 0.090 s\n",
      "2026-02-08 18:29:37,001 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:37,001 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:37,002 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:37,002 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:37,084 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:37,085 INFO scheduler.DAGScheduler: Got job 30 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:37,086 INFO scheduler.DAGScheduler: Final stage: ResultStage 44 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:37,087 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\n",
      "2026-02-08 18:29:37,087 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:37,087 INFO scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:37,091 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:37,093 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:37,093 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.2.196.57:46029 (size: 19.1 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:37,094 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:37,094 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:37,095 INFO cluster.YarnScheduler: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:37,096 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 34) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:37,124 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:39391 (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:37,129 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:37,149 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 34) in 53 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:37,149 INFO cluster.YarnScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:37,150 INFO scheduler.DAGScheduler: ResultStage 44 (collect at AnalysisRunner.scala:326) finished in 0.061 s\n",
      "2026-02-08 18:29:37,150 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:37,151 INFO cluster.YarnScheduler: Killing all running tasks in stage 44: Stage finished\n",
      "2026-02-08 18:29:37,151 INFO scheduler.DAGScheduler: Job 30 finished: collect at AnalysisRunner.scala:326, took 0.066991 s\n",
      "2026-02-08 18:29:37,230 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:37,231 INFO scheduler.DAGScheduler: Registering RDD 185 (countByKey at ColumnProfiler.scala:592) as input to shuffle 14\n",
      "2026-02-08 18:29:37,232 INFO scheduler.DAGScheduler: Got job 31 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:37,232 INFO scheduler.DAGScheduler: Final stage: ResultStage 46 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:37,232 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\n",
      "2026-02-08 18:29:37,233 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 45)\n",
      "2026-02-08 18:29:37,235 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:37,241 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 42.9 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:37,243 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:37,243 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:37,244 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:37,244 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:37,245 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:37,246 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 35) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:37,260 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:37,354 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 35) in 108 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:37,354 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:37,355 INFO scheduler.DAGScheduler: ShuffleMapStage 45 (countByKey at ColumnProfiler.scala:592) finished in 0.120 s\n",
      "2026-02-08 18:29:37,356 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:37,356 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:37,356 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 46)\n",
      "2026-02-08 18:29:37,357 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:37,357 INFO scheduler.DAGScheduler: Submitting ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:37,359 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:37,361 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:37,361 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:37,362 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:37,362 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:37,363 INFO cluster.YarnScheduler: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:37,364 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:37,378 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:37,384 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:37,414 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 50 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:37,414 INFO cluster.YarnScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:37,415 INFO scheduler.DAGScheduler: ResultStage 46 (countByKey at ColumnProfiler.scala:592) finished in 0.057 s\n",
      "2026-02-08 18:29:37,416 INFO scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:37,416 INFO cluster.YarnScheduler: Killing all running tasks in stage 46: Stage finished\n",
      "2026-02-08 18:29:37,417 INFO scheduler.DAGScheduler: Job 31 finished: countByKey at ColumnProfiler.scala:592, took 0.185723 s\n",
      "2026-02-08 18:29:37,594 INFO scheduler.DAGScheduler: Registering RDD 191 (collect at AnalysisRunner.scala:326) as input to shuffle 15\n",
      "2026-02-08 18:29:37,594 INFO scheduler.DAGScheduler: Got map stage job 32 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:37,594 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:37,594 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:37,595 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:37,595 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:37,600 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 95.7 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:37,602 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:37,603 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.2.196.57:46029 (size: 30.1 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:37,604 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:37,604 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:37,604 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:37,606 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 37) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:37,627 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:39391 (size: 30.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:37,790 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 37) in 184 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:37,790 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:37,791 INFO scheduler.DAGScheduler: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326) finished in 0.195 s\n",
      "2026-02-08 18:29:37,791 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:37,791 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:37,791 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:37,792 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:37,888 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:37,889 INFO scheduler.DAGScheduler: Got job 33 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:37,889 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:37,889 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\n",
      "2026-02-08 18:29:37,890 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:37,890 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:37,905 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 180.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:37,906 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:37,907 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.2.196.57:46029 (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:37,908 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:37,908 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:37,908 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:37,916 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 38) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:37,929 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:39391 (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:37,952 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:38,090 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 38) in 174 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:38,091 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:38,092 INFO scheduler.DAGScheduler: ResultStage 49 (collect at AnalysisRunner.scala:326) finished in 0.199 s\n",
      "2026-02-08 18:29:38,093 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:38,095 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\n",
      "2026-02-08 18:29:38,096 INFO scheduler.DAGScheduler: Job 33 finished: collect at AnalysisRunner.scala:326, took 0.207310 s\n",
      "2026-02-08 18:29:38,236 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:38,237 INFO scheduler.DAGScheduler: Got job 34 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:38,237 INFO scheduler.DAGScheduler: Final stage: ResultStage 50 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:38,237 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:38,239 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:38,239 INFO scheduler.DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:38,252 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 50.5 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:38,254 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:38,254 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:38,255 INFO spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:38,258 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:38,259 INFO cluster.YarnScheduler: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:38,266 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 39) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:38,280 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:38,409 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 39) in 149 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:38,410 INFO scheduler.DAGScheduler: ResultStage 50 (treeReduce at KLLRunner.scala:107) finished in 0.168 s\n",
      "2026-02-08 18:29:38,411 INFO cluster.YarnScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:38,411 INFO scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:38,411 INFO cluster.YarnScheduler: Killing all running tasks in stage 50: Stage finished\n",
      "2026-02-08 18:29:38,412 INFO scheduler.DAGScheduler: Job 34 finished: treeReduce at KLLRunner.scala:107, took 0.174908 s\n",
      "2026-02-08 18:29:38,662 INFO scheduler.DAGScheduler: Registering RDD 209 (collect at AnalysisRunner.scala:326) as input to shuffle 16\n",
      "2026-02-08 18:29:38,663 INFO scheduler.DAGScheduler: Got map stage job 35 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:38,663 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:38,663 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:38,664 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:38,664 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:38,669 INFO memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 86.4 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:38,672 INFO memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:38,673 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:38,673 INFO spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:38,674 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:38,674 INFO cluster.YarnScheduler: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:38,679 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 40) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:38,693 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:38,753 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 40) in 75 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:38,753 INFO cluster.YarnScheduler: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:38,754 INFO scheduler.DAGScheduler: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326) finished in 0.089 s\n",
      "2026-02-08 18:29:38,754 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:38,754 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:38,755 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:38,755 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:38,856 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:38,860 INFO scheduler.DAGScheduler: Got job 36 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:38,861 INFO scheduler.DAGScheduler: Final stage: ResultStage 53 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:38,861 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)\n",
      "2026-02-08 18:29:38,861 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:38,862 INFO scheduler.DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:38,865 INFO memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 66.2 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:38,867 INFO memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:38,868 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.2.196.57:46029 (size: 19.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:38,868 INFO spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:38,869 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:38,869 INFO cluster.YarnScheduler: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:38,871 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 41) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:38,881 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on algo-1:39391 (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:38,888 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:38,902 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 41) in 31 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:38,902 INFO cluster.YarnScheduler: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:38,903 INFO scheduler.DAGScheduler: ResultStage 53 (collect at AnalysisRunner.scala:326) finished in 0.040 s\n",
      "2026-02-08 18:29:38,904 INFO scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:38,904 INFO cluster.YarnScheduler: Killing all running tasks in stage 53: Stage finished\n",
      "2026-02-08 18:29:38,905 INFO scheduler.DAGScheduler: Job 36 finished: collect at AnalysisRunner.scala:326, took 0.044906 s\n",
      "2026-02-08 18:29:39,024 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:39,036 INFO scheduler.DAGScheduler: Registering RDD 220 (countByKey at ColumnProfiler.scala:592) as input to shuffle 17\n",
      "2026-02-08 18:29:39,036 INFO scheduler.DAGScheduler: Got job 37 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:39,037 INFO scheduler.DAGScheduler: Final stage: ResultStage 55 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:39,037 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)\n",
      "2026-02-08 18:29:39,037 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 54)\n",
      "2026-02-08 18:29:39,038 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:39,049 INFO memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 42.9 KiB, free 1456.7 MiB)\n",
      "2026-02-08 18:29:39,134 INFO memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1456.7 MiB)\n",
      "2026-02-08 18:29:39,138 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:39,138 INFO spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:39,141 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:39,141 INFO cluster.YarnScheduler: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:39,139 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,142 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 42) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:39,149 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:39,151 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,157 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on algo-1:39391 in memory (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,158 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.2.196.57:46029 in memory (size: 19.1 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:39,173 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:39,173 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,178 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:39,180 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,184 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.2.196.57:46029 in memory (size: 30.1 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:39,197 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on algo-1:39391 in memory (size: 30.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,207 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:39,216 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,221 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:39,223 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,227 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.2.196.57:46029 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:39,241 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on algo-1:39391 in memory (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,249 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:39,263 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,266 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.2.196.57:46029 in memory (size: 49.3 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:39,267 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on algo-1:39391 in memory (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,280 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 42) in 138 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:39,281 INFO cluster.YarnScheduler: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:39,282 INFO scheduler.DAGScheduler: ShuffleMapStage 54 (countByKey at ColumnProfiler.scala:592) finished in 0.243 s\n",
      "2026-02-08 18:29:39,283 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:39,283 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:39,283 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 55)\n",
      "2026-02-08 18:29:39,284 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:39,285 INFO scheduler.DAGScheduler: Submitting ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:39,286 INFO memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 5.1 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:39,289 INFO memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:39,290 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:39,290 INFO spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:39,291 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:39,291 INFO cluster.YarnScheduler: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:39,293 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 43) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:39,304 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,308 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:39,342 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 43) in 49 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:39,342 INFO cluster.YarnScheduler: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:39,343 INFO scheduler.DAGScheduler: ResultStage 55 (countByKey at ColumnProfiler.scala:592) finished in 0.057 s\n",
      "2026-02-08 18:29:39,344 INFO scheduler.DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:39,344 INFO cluster.YarnScheduler: Killing all running tasks in stage 55: Stage finished\n",
      "2026-02-08 18:29:39,345 INFO scheduler.DAGScheduler: Job 37 finished: countByKey at ColumnProfiler.scala:592, took 0.309280 s\n",
      "2026-02-08 18:29:39,633 INFO scheduler.DAGScheduler: Registering RDD 226 (collect at AnalysisRunner.scala:326) as input to shuffle 18\n",
      "2026-02-08 18:29:39,634 INFO scheduler.DAGScheduler: Got map stage job 38 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:39,634 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:39,634 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:39,636 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:39,637 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:39,645 INFO memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 95.7 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:39,652 INFO memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:39,656 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:39,657 INFO spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:39,658 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:39,658 INFO cluster.YarnScheduler: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:39,661 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 44) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:39,669 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,861 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 44) in 200 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:39,862 INFO cluster.YarnScheduler: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:39,863 INFO scheduler.DAGScheduler: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326) finished in 0.224 s\n",
      "2026-02-08 18:29:39,864 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:39,864 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:39,864 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:39,864 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:39,924 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:39,924 INFO scheduler.DAGScheduler: Got job 39 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:39,925 INFO scheduler.DAGScheduler: Final stage: ResultStage 58 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:39,925 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)\n",
      "2026-02-08 18:29:39,925 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:39,925 INFO scheduler.DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:39,932 INFO memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 180.4 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:39,934 INFO memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:39,935 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.2.196.57:46029 (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:39,935 INFO spark.SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:39,936 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:39,936 INFO cluster.YarnScheduler: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:39,937 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 58.0 (TID 45) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:39,949 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on algo-1:39391 (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:39,970 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:40,068 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 58.0 (TID 45) in 131 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:40,068 INFO cluster.YarnScheduler: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:40,069 INFO scheduler.DAGScheduler: ResultStage 58 (collect at AnalysisRunner.scala:326) finished in 0.142 s\n",
      "2026-02-08 18:29:40,069 INFO scheduler.DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:40,074 INFO cluster.YarnScheduler: Killing all running tasks in stage 58: Stage finished\n",
      "2026-02-08 18:29:40,075 INFO scheduler.DAGScheduler: Job 39 finished: collect at AnalysisRunner.scala:326, took 0.151116 s\n",
      "2026-02-08 18:29:40,227 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:40,228 INFO scheduler.DAGScheduler: Got job 40 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:40,229 INFO scheduler.DAGScheduler: Final stage: ResultStage 59 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:40,229 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:40,230 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:40,230 INFO scheduler.DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:40,235 INFO memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 50.5 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:40,237 INFO memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:40,237 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:40,238 INFO spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:40,238 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:40,238 INFO cluster.YarnScheduler: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:40,240 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 59.0 (TID 46) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:40,254 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:40,421 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 59.0 (TID 46) in 182 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:40,422 INFO cluster.YarnScheduler: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:40,423 INFO scheduler.DAGScheduler: ResultStage 59 (treeReduce at KLLRunner.scala:107) finished in 0.192 s\n",
      "2026-02-08 18:29:40,423 INFO scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:40,424 INFO cluster.YarnScheduler: Killing all running tasks in stage 59: Stage finished\n",
      "2026-02-08 18:29:40,424 INFO scheduler.DAGScheduler: Job 40 finished: treeReduce at KLLRunner.scala:107, took 0.196301 s\n",
      "2026-02-08 18:29:40,578 INFO scheduler.DAGScheduler: Registering RDD 244 (collect at AnalysisRunner.scala:326) as input to shuffle 19\n",
      "2026-02-08 18:29:40,579 INFO scheduler.DAGScheduler: Got map stage job 41 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:40,579 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:40,579 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:40,580 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:40,580 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:40,585 INFO memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 86.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:40,587 INFO memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:40,587 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:40,589 INFO spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:40,589 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:40,589 INFO cluster.YarnScheduler: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:40,591 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 60.0 (TID 47) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:40,609 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:40,642 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 60.0 (TID 47) in 52 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:40,647 INFO cluster.YarnScheduler: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:40,648 INFO scheduler.DAGScheduler: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326) finished in 0.066 s\n",
      "2026-02-08 18:29:40,648 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:40,648 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:40,648 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:40,649 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:40,723 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:40,724 INFO scheduler.DAGScheduler: Got job 42 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:40,725 INFO scheduler.DAGScheduler: Final stage: ResultStage 62 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:40,725 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)\n",
      "2026-02-08 18:29:40,725 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:40,726 INFO scheduler.DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:40,729 INFO memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 66.2 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:40,732 INFO memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:40,734 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.2.196.57:46029 (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:40,736 INFO spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:40,736 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:40,736 INFO cluster.YarnScheduler: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:40,738 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 62.0 (TID 48) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:40,755 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on algo-1:39391 (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:40,762 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:40,774 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 62.0 (TID 48) in 36 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:40,774 INFO cluster.YarnScheduler: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:40,775 INFO scheduler.DAGScheduler: ResultStage 62 (collect at AnalysisRunner.scala:326) finished in 0.048 s\n",
      "2026-02-08 18:29:40,776 INFO scheduler.DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:40,776 INFO cluster.YarnScheduler: Killing all running tasks in stage 62: Stage finished\n",
      "2026-02-08 18:29:40,777 INFO scheduler.DAGScheduler: Job 42 finished: collect at AnalysisRunner.scala:326, took 0.053496 s\n",
      "2026-02-08 18:29:40,854 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:40,855 INFO scheduler.DAGScheduler: Registering RDD 255 (countByKey at ColumnProfiler.scala:592) as input to shuffle 20\n",
      "2026-02-08 18:29:40,856 INFO scheduler.DAGScheduler: Got job 43 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:40,856 INFO scheduler.DAGScheduler: Final stage: ResultStage 64 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:40,856 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)\n",
      "2026-02-08 18:29:40,857 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 63)\n",
      "2026-02-08 18:29:40,859 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:40,864 INFO memory.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 42.9 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:40,866 INFO memory.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:40,867 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:40,868 INFO spark.SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:40,868 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:40,868 INFO cluster.YarnScheduler: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:40,870 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 63.0 (TID 49) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:40,879 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:40,931 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 63.0 (TID 49) in 62 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:40,932 INFO cluster.YarnScheduler: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:40,933 INFO scheduler.DAGScheduler: ShuffleMapStage 63 (countByKey at ColumnProfiler.scala:592) finished in 0.073 s\n",
      "2026-02-08 18:29:40,934 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:40,934 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:40,934 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 64)\n",
      "2026-02-08 18:29:40,935 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:40,935 INFO scheduler.DAGScheduler: Submitting ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:40,937 INFO memory.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 5.1 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:40,939 INFO memory.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:40,939 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:40,940 INFO spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:40,940 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:40,941 INFO cluster.YarnScheduler: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:40,942 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 64.0 (TID 50) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:40,953 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:40,957 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:40,975 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 64.0 (TID 50) in 33 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:40,976 INFO cluster.YarnScheduler: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:40,976 INFO scheduler.DAGScheduler: ResultStage 64 (countByKey at ColumnProfiler.scala:592) finished in 0.040 s\n",
      "2026-02-08 18:29:40,977 INFO scheduler.DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:40,978 INFO cluster.YarnScheduler: Killing all running tasks in stage 64: Stage finished\n",
      "2026-02-08 18:29:40,979 INFO scheduler.DAGScheduler: Job 43 finished: countByKey at ColumnProfiler.scala:592, took 0.124296 s\n",
      "2026-02-08 18:29:41,052 INFO scheduler.DAGScheduler: Registering RDD 261 (collect at AnalysisRunner.scala:326) as input to shuffle 21\n",
      "2026-02-08 18:29:41,053 INFO scheduler.DAGScheduler: Got map stage job 44 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:41,053 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:41,054 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:41,054 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:41,055 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:41,060 INFO memory.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 95.7 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:41,062 INFO memory.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:41,062 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:41,063 INFO spark.SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:41,064 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:41,064 INFO cluster.YarnScheduler: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:41,065 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 65.0 (TID 51) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:41,075 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:41,252 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 65.0 (TID 51) in 187 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:41,252 INFO cluster.YarnScheduler: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:41,253 INFO scheduler.DAGScheduler: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326) finished in 0.197 s\n",
      "2026-02-08 18:29:41,255 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:41,255 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:41,255 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:41,256 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:41,306 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:41,307 INFO scheduler.DAGScheduler: Got job 45 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:41,307 INFO scheduler.DAGScheduler: Final stage: ResultStage 67 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:41,308 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\n",
      "2026-02-08 18:29:41,308 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:41,309 INFO scheduler.DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:41,322 INFO memory.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 180.4 KiB, free 1456.7 MiB)\n",
      "2026-02-08 18:29:41,324 INFO memory.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 49.4 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:41,325 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.2.196.57:46029 (size: 49.4 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:41,326 INFO spark.SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:41,326 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:41,327 INFO cluster.YarnScheduler: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:41,328 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 67.0 (TID 52) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:41,337 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on algo-1:39391 (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:41,347 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:41,446 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 67.0 (TID 52) in 118 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:41,446 INFO cluster.YarnScheduler: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:41,447 INFO scheduler.DAGScheduler: ResultStage 67 (collect at AnalysisRunner.scala:326) finished in 0.132 s\n",
      "2026-02-08 18:29:41,450 INFO scheduler.DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:41,451 INFO cluster.YarnScheduler: Killing all running tasks in stage 67: Stage finished\n",
      "2026-02-08 18:29:41,452 INFO scheduler.DAGScheduler: Job 45 finished: collect at AnalysisRunner.scala:326, took 0.145378 s\n",
      "2026-02-08 18:29:41,595 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:41,596 INFO scheduler.DAGScheduler: Got job 46 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:41,596 INFO scheduler.DAGScheduler: Final stage: ResultStage 68 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:41,596 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:41,597 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:41,598 INFO scheduler.DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:41,606 INFO memory.MemoryStore: Block broadcast_55 stored as values in memory (estimated size 50.5 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:41,608 INFO memory.MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:41,609 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:41,609 INFO spark.SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:41,610 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:41,610 INFO cluster.YarnScheduler: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:41,611 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 68.0 (TID 53) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:41,628 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:41,831 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 68.0 (TID 53) in 219 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:41,839 INFO scheduler.DAGScheduler: ResultStage 68 (treeReduce at KLLRunner.scala:107) finished in 0.240 s\n",
      "2026-02-08 18:29:41,840 INFO scheduler.DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:41,840 INFO cluster.YarnScheduler: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:41,840 INFO cluster.YarnScheduler: Killing all running tasks in stage 68: Stage finished\n",
      "2026-02-08 18:29:41,841 INFO scheduler.DAGScheduler: Job 46 finished: treeReduce at KLLRunner.scala:107, took 0.245052 s\n",
      "2026-02-08 18:29:42,101 INFO scheduler.DAGScheduler: Registering RDD 279 (collect at AnalysisRunner.scala:326) as input to shuffle 22\n",
      "2026-02-08 18:29:42,102 INFO scheduler.DAGScheduler: Got map stage job 47 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:42,102 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:42,102 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:42,103 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:42,103 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:42,112 INFO memory.MemoryStore: Block broadcast_56 stored as values in memory (estimated size 86.4 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:42,114 INFO memory.MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:42,115 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:42,115 INFO spark.SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:42,116 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:42,116 INFO cluster.YarnScheduler: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:42,117 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 69.0 (TID 54) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:42,126 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,180 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 69.0 (TID 54) in 63 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:42,180 INFO cluster.YarnScheduler: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:42,181 INFO scheduler.DAGScheduler: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326) finished in 0.073 s\n",
      "2026-02-08 18:29:42,181 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:42,182 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:42,182 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:42,182 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:42,285 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:42,286 INFO scheduler.DAGScheduler: Got job 48 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:42,287 INFO scheduler.DAGScheduler: Final stage: ResultStage 71 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:42,287 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)\n",
      "2026-02-08 18:29:42,287 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:42,287 INFO scheduler.DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:42,289 INFO memory.MemoryStore: Block broadcast_57 stored as values in memory (estimated size 66.2 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:42,292 INFO memory.MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:42,293 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.2.196.57:46029 (size: 19.1 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:42,293 INFO spark.SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:42,293 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:42,294 INFO cluster.YarnScheduler: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:42,295 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 71.0 (TID 55) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:42,303 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on algo-1:39391 (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,307 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:42,313 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 71.0 (TID 55) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:42,314 INFO cluster.YarnScheduler: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:42,315 INFO scheduler.DAGScheduler: ResultStage 71 (collect at AnalysisRunner.scala:326) finished in 0.027 s\n",
      "2026-02-08 18:29:42,321 INFO scheduler.DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:42,321 INFO cluster.YarnScheduler: Killing all running tasks in stage 71: Stage finished\n",
      "2026-02-08 18:29:42,322 INFO scheduler.DAGScheduler: Job 48 finished: collect at AnalysisRunner.scala:326, took 0.036241 s\n",
      "2026-02-08 18:29:42,396 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on algo-1:39391 in memory (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,398 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on 10.2.196.57:46029 in memory (size: 49.4 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:42,402 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,403 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:42,419 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:42,421 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,427 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,430 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:42,442 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,445 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:42,452 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,456 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:42,460 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on algo-1:39391 in memory (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,461 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on 10.2.196.57:46029 in memory (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:42,464 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:42,466 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,477 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,487 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:42,496 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on 10.2.196.57:46029 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:42,497 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on algo-1:39391 in memory (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,500 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:42,501 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,505 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:42,507 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,509 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on 10.2.196.57:46029 in memory (size: 19.1 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:42,511 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on algo-1:39391 in memory (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,527 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:42,531 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,545 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:42,547 INFO scheduler.DAGScheduler: Registering RDD 290 (countByKey at ColumnProfiler.scala:592) as input to shuffle 23\n",
      "2026-02-08 18:29:42,547 INFO scheduler.DAGScheduler: Got job 49 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:42,547 INFO scheduler.DAGScheduler: Final stage: ResultStage 73 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:42,548 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)\n",
      "2026-02-08 18:29:42,548 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 72)\n",
      "2026-02-08 18:29:42,549 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:42,557 INFO memory.MemoryStore: Block broadcast_58 stored as values in memory (estimated size 42.9 KiB, free 1457.7 MiB)\n",
      "2026-02-08 18:29:42,559 INFO memory.MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.7 MiB)\n",
      "2026-02-08 18:29:42,559 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:42,560 INFO spark.SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:42,560 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:42,561 INFO cluster.YarnScheduler: Adding task set 72.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:42,562 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 72.0 (TID 56) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:42,573 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,645 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 72.0 (TID 56) in 83 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:42,645 INFO cluster.YarnScheduler: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:42,646 INFO scheduler.DAGScheduler: ShuffleMapStage 72 (countByKey at ColumnProfiler.scala:592) finished in 0.096 s\n",
      "2026-02-08 18:29:42,652 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:42,653 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:42,653 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 73)\n",
      "2026-02-08 18:29:42,654 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:42,654 INFO scheduler.DAGScheduler: Submitting ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:42,656 INFO memory.MemoryStore: Block broadcast_59 stored as values in memory (estimated size 5.1 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:42,657 INFO memory.MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:42,658 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:42,659 INFO spark.SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:42,659 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:42,659 INFO cluster.YarnScheduler: Adding task set 73.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:42,661 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 73.0 (TID 57) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:42,670 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:42,673 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:42,697 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 73.0 (TID 57) in 36 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:42,698 INFO cluster.YarnScheduler: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:42,699 INFO scheduler.DAGScheduler: ResultStage 73 (countByKey at ColumnProfiler.scala:592) finished in 0.044 s\n",
      "2026-02-08 18:29:42,700 INFO scheduler.DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:42,700 INFO cluster.YarnScheduler: Killing all running tasks in stage 73: Stage finished\n",
      "2026-02-08 18:29:42,700 INFO scheduler.DAGScheduler: Job 49 finished: countByKey at ColumnProfiler.scala:592, took 0.154310 s\n",
      "2026-02-08 18:29:42,901 INFO scheduler.DAGScheduler: Registering RDD 296 (collect at AnalysisRunner.scala:326) as input to shuffle 24\n",
      "2026-02-08 18:29:42,901 INFO scheduler.DAGScheduler: Got map stage job 50 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:42,902 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:42,902 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:42,902 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:42,903 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:42,911 INFO memory.MemoryStore: Block broadcast_60 stored as values in memory (estimated size 95.7 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:42,913 INFO memory.MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:42,913 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:42,914 INFO spark.SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:42,915 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:42,915 INFO cluster.YarnScheduler: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:42,916 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 74.0 (TID 58) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:42,939 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:43,063 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 74.0 (TID 58) in 147 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:43,063 INFO cluster.YarnScheduler: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:43,064 INFO scheduler.DAGScheduler: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326) finished in 0.158 s\n",
      "2026-02-08 18:29:43,065 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:43,066 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:43,067 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:43,067 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:43,126 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:43,127 INFO scheduler.DAGScheduler: Got job 51 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:43,127 INFO scheduler.DAGScheduler: Final stage: ResultStage 76 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:43,127 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)\n",
      "2026-02-08 18:29:43,127 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:43,127 INFO scheduler.DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:43,135 INFO memory.MemoryStore: Block broadcast_61 stored as values in memory (estimated size 180.4 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:43,137 INFO memory.MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:43,137 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.2.196.57:46029 (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:43,138 INFO spark.SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:43,138 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:43,138 INFO cluster.YarnScheduler: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:43,141 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 76.0 (TID 59) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:43,150 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on algo-1:39391 (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:43,158 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:43,256 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 76.0 (TID 59) in 115 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:43,256 INFO cluster.YarnScheduler: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:43,257 INFO scheduler.DAGScheduler: ResultStage 76 (collect at AnalysisRunner.scala:326) finished in 0.129 s\n",
      "2026-02-08 18:29:43,262 INFO scheduler.DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:43,263 INFO cluster.YarnScheduler: Killing all running tasks in stage 76: Stage finished\n",
      "2026-02-08 18:29:43,263 INFO scheduler.DAGScheduler: Job 51 finished: collect at AnalysisRunner.scala:326, took 0.136906 s\n",
      "2026-02-08 18:29:43,434 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:43,438 INFO scheduler.DAGScheduler: Got job 52 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:43,439 INFO scheduler.DAGScheduler: Final stage: ResultStage 77 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:43,439 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:43,440 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:43,440 INFO scheduler.DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:43,446 INFO memory.MemoryStore: Block broadcast_62 stored as values in memory (estimated size 50.5 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:43,453 INFO memory.MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:43,454 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:43,455 INFO spark.SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:43,455 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:43,456 INFO cluster.YarnScheduler: Adding task set 77.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:43,465 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 77.0 (TID 60) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:43,474 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:43,651 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 77.0 (TID 60) in 186 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:43,655 INFO scheduler.DAGScheduler: ResultStage 77 (treeReduce at KLLRunner.scala:107) finished in 0.212 s\n",
      "2026-02-08 18:29:43,655 INFO scheduler.DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:43,656 INFO cluster.YarnScheduler: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:43,656 INFO cluster.YarnScheduler: Killing all running tasks in stage 77: Stage finished\n",
      "2026-02-08 18:29:43,656 INFO scheduler.DAGScheduler: Job 52 finished: treeReduce at KLLRunner.scala:107, took 0.219062 s\n",
      "2026-02-08 18:29:43,798 INFO scheduler.DAGScheduler: Registering RDD 314 (collect at AnalysisRunner.scala:326) as input to shuffle 25\n",
      "2026-02-08 18:29:43,798 INFO scheduler.DAGScheduler: Got map stage job 53 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:43,799 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:43,799 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:43,799 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:43,800 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:43,803 INFO memory.MemoryStore: Block broadcast_63 stored as values in memory (estimated size 86.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:43,805 INFO memory.MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:43,806 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:43,806 INFO spark.SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:43,807 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:43,807 INFO cluster.YarnScheduler: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:43,808 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 78.0 (TID 61) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:43,817 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:43,842 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 78.0 (TID 61) in 34 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:43,842 INFO cluster.YarnScheduler: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:43,843 INFO scheduler.DAGScheduler: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326) finished in 0.042 s\n",
      "2026-02-08 18:29:43,843 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:43,843 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:43,844 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:43,844 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:43,897 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:43,898 INFO scheduler.DAGScheduler: Got job 54 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:43,898 INFO scheduler.DAGScheduler: Final stage: ResultStage 80 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:43,898 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)\n",
      "2026-02-08 18:29:43,899 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:43,899 INFO scheduler.DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:43,900 INFO memory.MemoryStore: Block broadcast_64 stored as values in memory (estimated size 66.2 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:43,902 INFO memory.MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:43,902 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.2.196.57:46029 (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:43,902 INFO spark.SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:43,903 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:43,903 INFO cluster.YarnScheduler: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:43,904 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 80.0 (TID 62) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:43,913 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on algo-1:39391 (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:43,918 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:43,925 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 80.0 (TID 62) in 21 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:43,925 INFO cluster.YarnScheduler: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:43,925 INFO scheduler.DAGScheduler: ResultStage 80 (collect at AnalysisRunner.scala:326) finished in 0.026 s\n",
      "2026-02-08 18:29:43,925 INFO scheduler.DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:43,925 INFO cluster.YarnScheduler: Killing all running tasks in stage 80: Stage finished\n",
      "2026-02-08 18:29:43,927 INFO scheduler.DAGScheduler: Job 54 finished: collect at AnalysisRunner.scala:326, took 0.028562 s\n",
      "2026-02-08 18:29:43,994 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:43,995 INFO scheduler.DAGScheduler: Registering RDD 325 (countByKey at ColumnProfiler.scala:592) as input to shuffle 26\n",
      "2026-02-08 18:29:43,995 INFO scheduler.DAGScheduler: Got job 55 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:43,996 INFO scheduler.DAGScheduler: Final stage: ResultStage 82 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:43,996 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)\n",
      "2026-02-08 18:29:43,996 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 81)\n",
      "2026-02-08 18:29:43,997 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:44,000 INFO memory.MemoryStore: Block broadcast_65 stored as values in memory (estimated size 42.9 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:44,002 INFO memory.MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:44,002 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:44,003 INFO spark.SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:44,003 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:44,003 INFO cluster.YarnScheduler: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:44,004 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 81.0 (TID 63) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:44,014 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:44,058 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 81.0 (TID 63) in 54 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:44,058 INFO cluster.YarnScheduler: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:44,059 INFO scheduler.DAGScheduler: ShuffleMapStage 81 (countByKey at ColumnProfiler.scala:592) finished in 0.060 s\n",
      "2026-02-08 18:29:44,059 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:44,059 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:44,059 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 82)\n",
      "2026-02-08 18:29:44,059 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:44,059 INFO scheduler.DAGScheduler: Submitting ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:44,060 INFO memory.MemoryStore: Block broadcast_66 stored as values in memory (estimated size 5.1 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:44,062 INFO memory.MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:44,062 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:44,063 INFO spark.SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:44,063 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:44,064 INFO cluster.YarnScheduler: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:44,065 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 82.0 (TID 64) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:44,073 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:44,076 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:44,096 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 82.0 (TID 64) in 30 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:44,096 INFO cluster.YarnScheduler: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:44,096 INFO scheduler.DAGScheduler: ResultStage 82 (countByKey at ColumnProfiler.scala:592) finished in 0.037 s\n",
      "2026-02-08 18:29:44,097 INFO scheduler.DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:44,097 INFO cluster.YarnScheduler: Killing all running tasks in stage 82: Stage finished\n",
      "2026-02-08 18:29:44,097 INFO scheduler.DAGScheduler: Job 55 finished: countByKey at ColumnProfiler.scala:592, took 0.102945 s\n",
      "2026-02-08 18:29:44,196 INFO scheduler.DAGScheduler: Registering RDD 331 (collect at AnalysisRunner.scala:326) as input to shuffle 27\n",
      "2026-02-08 18:29:44,196 INFO scheduler.DAGScheduler: Got map stage job 56 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:44,196 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:44,196 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:44,197 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:44,197 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:44,201 INFO memory.MemoryStore: Block broadcast_67 stored as values in memory (estimated size 95.7 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:44,203 INFO memory.MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:44,203 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:44,204 INFO spark.SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:44,204 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:44,205 INFO cluster.YarnScheduler: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:44,206 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 83.0 (TID 65) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:44,215 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:44,405 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 83.0 (TID 65) in 199 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:44,407 INFO cluster.YarnScheduler: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:44,408 INFO scheduler.DAGScheduler: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326) finished in 0.210 s\n",
      "2026-02-08 18:29:44,408 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:44,408 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:44,408 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:44,408 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:44,446 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:44,447 INFO scheduler.DAGScheduler: Got job 57 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:44,448 INFO scheduler.DAGScheduler: Final stage: ResultStage 85 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:44,448 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)\n",
      "2026-02-08 18:29:44,448 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:44,450 INFO scheduler.DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:44,459 INFO memory.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 180.4 KiB, free 1456.7 MiB)\n",
      "2026-02-08 18:29:44,461 INFO memory.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 49.4 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:44,461 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.2.196.57:46029 (size: 49.4 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:44,462 INFO spark.SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:44,463 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:44,463 INFO cluster.YarnScheduler: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:44,464 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 85.0 (TID 66) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:44,472 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on algo-1:39391 (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:44,483 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:44,576 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 85.0 (TID 66) in 112 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:44,576 INFO cluster.YarnScheduler: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:44,577 INFO scheduler.DAGScheduler: ResultStage 85 (collect at AnalysisRunner.scala:326) finished in 0.127 s\n",
      "2026-02-08 18:29:44,579 INFO scheduler.DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:44,579 INFO cluster.YarnScheduler: Killing all running tasks in stage 85: Stage finished\n",
      "2026-02-08 18:29:44,579 INFO scheduler.DAGScheduler: Job 57 finished: collect at AnalysisRunner.scala:326, took 0.132540 s\n",
      "2026-02-08 18:29:44,693 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:44,693 INFO scheduler.DAGScheduler: Got job 58 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:44,694 INFO scheduler.DAGScheduler: Final stage: ResultStage 86 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:44,694 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:44,694 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:44,694 INFO scheduler.DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:44,699 INFO memory.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 50.5 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:44,701 INFO memory.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:44,704 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:44,704 INFO spark.SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:44,705 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:44,705 INFO cluster.YarnScheduler: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:44,706 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 86.0 (TID 67) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:44,715 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:44,821 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 86.0 (TID 67) in 115 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:44,822 INFO cluster.YarnScheduler: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:44,823 INFO scheduler.DAGScheduler: ResultStage 86 (treeReduce at KLLRunner.scala:107) finished in 0.126 s\n",
      "2026-02-08 18:29:44,823 INFO scheduler.DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:44,823 INFO cluster.YarnScheduler: Killing all running tasks in stage 86: Stage finished\n",
      "2026-02-08 18:29:44,824 INFO scheduler.DAGScheduler: Job 58 finished: treeReduce at KLLRunner.scala:107, took 0.130675 s\n",
      "2026-02-08 18:29:45,022 INFO scheduler.DAGScheduler: Registering RDD 349 (collect at AnalysisRunner.scala:326) as input to shuffle 28\n",
      "2026-02-08 18:29:45,022 INFO scheduler.DAGScheduler: Got map stage job 59 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:45,023 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:45,023 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:45,023 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:45,024 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:45,026 INFO memory.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 86.4 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:45,029 INFO memory.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:45,029 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:45,030 INFO spark.SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:45,030 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:45,030 INFO cluster.YarnScheduler: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:45,032 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 87.0 (TID 68) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:45,043 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,080 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 87.0 (TID 68) in 49 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:45,081 INFO cluster.YarnScheduler: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:45,081 INFO scheduler.DAGScheduler: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326) finished in 0.056 s\n",
      "2026-02-08 18:29:45,082 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:45,083 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:45,083 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:45,083 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:45,181 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:45,184 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,189 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:45,190 INFO scheduler.DAGScheduler: Got job 60 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:45,191 INFO scheduler.DAGScheduler: Final stage: ResultStage 89 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:45,191 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\n",
      "2026-02-08 18:29:45,191 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:45,191 INFO scheduler.DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:45,195 INFO memory.MemoryStore: Block broadcast_71 stored as values in memory (estimated size 66.2 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:45,196 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:45,201 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,204 INFO memory.MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:45,205 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:45,206 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.2.196.57:46029 (size: 19.1 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:45,207 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,208 INFO spark.SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:45,209 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:45,210 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,211 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:45,211 INFO cluster.YarnScheduler: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:45,224 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:45,229 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,231 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 89.0 (TID 69) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:45,239 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:45,244 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,244 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on algo-1:39391 (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,250 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:45,250 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:45,254 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,257 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 89.0 (TID 69) in 26 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:45,257 INFO cluster.YarnScheduler: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:45,259 INFO scheduler.DAGScheduler: ResultStage 89 (collect at AnalysisRunner.scala:326) finished in 0.064 s\n",
      "2026-02-08 18:29:45,259 INFO scheduler.DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:45,259 INFO cluster.YarnScheduler: Killing all running tasks in stage 89: Stage finished\n",
      "2026-02-08 18:29:45,260 INFO scheduler.DAGScheduler: Job 60 finished: collect at AnalysisRunner.scala:326, took 0.070473 s\n",
      "2026-02-08 18:29:45,268 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on 10.2.196.57:46029 in memory (size: 19.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:45,269 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on algo-1:39391 in memory (size: 19.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,280 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on 10.2.196.57:46029 in memory (size: 49.4 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:45,280 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on algo-1:39391 in memory (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,284 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:45,284 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,291 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on 10.2.196.57:46029 in memory (size: 49.3 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:45,292 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on algo-1:39391 in memory (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,297 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:45,300 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,303 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:45,303 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,348 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:45,349 INFO scheduler.DAGScheduler: Registering RDD 360 (countByKey at ColumnProfiler.scala:592) as input to shuffle 29\n",
      "2026-02-08 18:29:45,350 INFO scheduler.DAGScheduler: Got job 61 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:45,350 INFO scheduler.DAGScheduler: Final stage: ResultStage 91 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:45,350 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\n",
      "2026-02-08 18:29:45,350 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 90)\n",
      "2026-02-08 18:29:45,351 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:45,357 INFO memory.MemoryStore: Block broadcast_72 stored as values in memory (estimated size 42.9 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:45,358 INFO memory.MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:45,358 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:45,359 INFO spark.SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:45,359 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:45,359 INFO cluster.YarnScheduler: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:45,360 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 90.0 (TID 70) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:45,369 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,468 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 90.0 (TID 70) in 108 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:45,468 INFO cluster.YarnScheduler: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:45,469 INFO scheduler.DAGScheduler: ShuffleMapStage 90 (countByKey at ColumnProfiler.scala:592) finished in 0.117 s\n",
      "2026-02-08 18:29:45,469 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:45,469 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:45,470 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 91)\n",
      "2026-02-08 18:29:45,470 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:45,470 INFO scheduler.DAGScheduler: Submitting ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:45,471 INFO memory.MemoryStore: Block broadcast_73 stored as values in memory (estimated size 5.1 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:45,473 INFO memory.MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:45,473 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:45,474 INFO spark.SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:45,474 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:45,474 INFO cluster.YarnScheduler: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:45,475 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 91.0 (TID 71) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:45,485 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,488 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:45,522 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 91.0 (TID 71) in 47 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:45,522 INFO cluster.YarnScheduler: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:45,523 INFO scheduler.DAGScheduler: ResultStage 91 (countByKey at ColumnProfiler.scala:592) finished in 0.052 s\n",
      "2026-02-08 18:29:45,523 INFO scheduler.DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:45,523 INFO cluster.YarnScheduler: Killing all running tasks in stage 91: Stage finished\n",
      "2026-02-08 18:29:45,524 INFO scheduler.DAGScheduler: Job 61 finished: countByKey at ColumnProfiler.scala:592, took 0.174951 s\n",
      "2026-02-08 18:29:45,689 INFO scheduler.DAGScheduler: Registering RDD 366 (collect at AnalysisRunner.scala:326) as input to shuffle 30\n",
      "2026-02-08 18:29:45,689 INFO scheduler.DAGScheduler: Got map stage job 62 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:45,689 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:45,689 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:45,690 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:45,690 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:45,695 INFO memory.MemoryStore: Block broadcast_74 stored as values in memory (estimated size 95.7 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:45,696 INFO memory.MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:45,697 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.2.196.57:46029 (size: 30.1 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:45,697 INFO spark.SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:45,698 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:45,698 INFO cluster.YarnScheduler: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:45,699 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 92.0 (TID 72) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:45,709 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on algo-1:39391 (size: 30.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,858 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 92.0 (TID 72) in 159 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:45,858 INFO cluster.YarnScheduler: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:45,859 INFO scheduler.DAGScheduler: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326) finished in 0.168 s\n",
      "2026-02-08 18:29:45,859 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:45,860 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:45,860 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:45,860 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:45,889 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:45,890 INFO scheduler.DAGScheduler: Got job 63 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:45,890 INFO scheduler.DAGScheduler: Final stage: ResultStage 94 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:45,890 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)\n",
      "2026-02-08 18:29:45,890 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:45,891 INFO scheduler.DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:45,899 INFO memory.MemoryStore: Block broadcast_75 stored as values in memory (estimated size 180.4 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:45,902 INFO memory.MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:45,903 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.2.196.57:46029 (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:45,903 INFO spark.SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:45,904 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:45,904 INFO cluster.YarnScheduler: Adding task set 94.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:45,905 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 94.0 (TID 73) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:45,912 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on algo-1:39391 (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:45,937 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:46,026 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 94.0 (TID 73) in 121 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:46,026 INFO cluster.YarnScheduler: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:46,027 INFO scheduler.DAGScheduler: ResultStage 94 (collect at AnalysisRunner.scala:326) finished in 0.135 s\n",
      "2026-02-08 18:29:46,027 INFO scheduler.DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:46,028 INFO cluster.YarnScheduler: Killing all running tasks in stage 94: Stage finished\n",
      "2026-02-08 18:29:46,028 INFO scheduler.DAGScheduler: Job 63 finished: collect at AnalysisRunner.scala:326, took 0.139027 s\n",
      "2026-02-08 18:29:46,118 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:46,119 INFO scheduler.DAGScheduler: Got job 64 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:46,119 INFO scheduler.DAGScheduler: Final stage: ResultStage 95 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:46,119 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:46,119 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:46,120 INFO scheduler.DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:46,124 INFO memory.MemoryStore: Block broadcast_76 stored as values in memory (estimated size 50.5 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:46,125 INFO memory.MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:46,125 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:46,126 INFO spark.SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:46,126 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:46,126 INFO cluster.YarnScheduler: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:46,128 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 95.0 (TID 74) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:46,134 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:46,266 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 95.0 (TID 74) in 139 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:46,267 INFO cluster.YarnScheduler: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:46,269 INFO scheduler.DAGScheduler: ResultStage 95 (treeReduce at KLLRunner.scala:107) finished in 0.148 s\n",
      "2026-02-08 18:29:46,274 INFO scheduler.DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:46,274 INFO cluster.YarnScheduler: Killing all running tasks in stage 95: Stage finished\n",
      "2026-02-08 18:29:46,274 INFO scheduler.DAGScheduler: Job 64 finished: treeReduce at KLLRunner.scala:107, took 0.156348 s\n",
      "2026-02-08 18:29:46,390 INFO scheduler.DAGScheduler: Registering RDD 384 (collect at AnalysisRunner.scala:326) as input to shuffle 31\n",
      "2026-02-08 18:29:46,391 INFO scheduler.DAGScheduler: Got map stage job 65 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:46,391 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:46,391 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:46,391 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:46,391 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:46,394 INFO memory.MemoryStore: Block broadcast_77 stored as values in memory (estimated size 86.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:46,396 INFO memory.MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:46,396 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:46,397 INFO spark.SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:46,397 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:46,397 INFO cluster.YarnScheduler: Adding task set 96.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:46,399 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 96.0 (TID 75) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:46,406 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:46,434 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 96.0 (TID 75) in 36 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:46,434 INFO cluster.YarnScheduler: Removed TaskSet 96.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:46,435 INFO scheduler.DAGScheduler: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326) finished in 0.043 s\n",
      "2026-02-08 18:29:46,435 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:46,435 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:46,435 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:46,435 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:46,475 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:46,476 INFO scheduler.DAGScheduler: Got job 66 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:46,476 INFO scheduler.DAGScheduler: Final stage: ResultStage 98 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:46,477 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)\n",
      "2026-02-08 18:29:46,477 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:46,477 INFO scheduler.DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:46,479 INFO memory.MemoryStore: Block broadcast_78 stored as values in memory (estimated size 66.2 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:46,481 INFO memory.MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:46,481 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.2.196.57:46029 (size: 19.1 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:46,482 INFO spark.SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:46,482 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:46,482 INFO cluster.YarnScheduler: Adding task set 98.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:46,484 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 98.0 (TID 76) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:46,494 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on algo-1:39391 (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:46,501 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:46,514 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 98.0 (TID 76) in 30 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:46,515 INFO cluster.YarnScheduler: Removed TaskSet 98.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:46,515 INFO scheduler.DAGScheduler: ResultStage 98 (collect at AnalysisRunner.scala:326) finished in 0.037 s\n",
      "2026-02-08 18:29:46,516 INFO scheduler.DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:46,517 INFO cluster.YarnScheduler: Killing all running tasks in stage 98: Stage finished\n",
      "2026-02-08 18:29:46,517 INFO scheduler.DAGScheduler: Job 66 finished: collect at AnalysisRunner.scala:326, took 0.041538 s\n",
      "2026-02-08 18:29:46,598 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:46,599 INFO scheduler.DAGScheduler: Registering RDD 395 (countByKey at ColumnProfiler.scala:592) as input to shuffle 32\n",
      "2026-02-08 18:29:46,600 INFO scheduler.DAGScheduler: Got job 67 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:46,600 INFO scheduler.DAGScheduler: Final stage: ResultStage 100 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:46,600 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)\n",
      "2026-02-08 18:29:46,601 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 99)\n",
      "2026-02-08 18:29:46,602 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:46,606 INFO memory.MemoryStore: Block broadcast_79 stored as values in memory (estimated size 42.9 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:46,607 INFO memory.MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:46,608 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:46,608 INFO spark.SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:46,609 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:46,609 INFO cluster.YarnScheduler: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:46,610 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 99.0 (TID 77) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:46,618 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:46,668 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 99.0 (TID 77) in 58 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:46,668 INFO cluster.YarnScheduler: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:46,669 INFO scheduler.DAGScheduler: ShuffleMapStage 99 (countByKey at ColumnProfiler.scala:592) finished in 0.066 s\n",
      "2026-02-08 18:29:46,671 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:46,671 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:46,672 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 100)\n",
      "2026-02-08 18:29:46,672 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:46,672 INFO scheduler.DAGScheduler: Submitting ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:46,674 INFO memory.MemoryStore: Block broadcast_80 stored as values in memory (estimated size 5.1 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:46,676 INFO memory.MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:46,676 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:46,677 INFO spark.SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:46,677 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:46,677 INFO cluster.YarnScheduler: Adding task set 100.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:46,678 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 78) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:46,690 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:46,698 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:46,722 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 78) in 44 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:46,729 INFO cluster.YarnScheduler: Removed TaskSet 100.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:46,731 INFO scheduler.DAGScheduler: ResultStage 100 (countByKey at ColumnProfiler.scala:592) finished in 0.057 s\n",
      "2026-02-08 18:29:46,731 INFO scheduler.DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:46,732 INFO cluster.YarnScheduler: Killing all running tasks in stage 100: Stage finished\n",
      "2026-02-08 18:29:46,732 INFO scheduler.DAGScheduler: Job 67 finished: countByKey at ColumnProfiler.scala:592, took 0.133436 s\n",
      "2026-02-08 18:29:46,866 INFO scheduler.DAGScheduler: Registering RDD 401 (collect at AnalysisRunner.scala:326) as input to shuffle 33\n",
      "2026-02-08 18:29:46,867 INFO scheduler.DAGScheduler: Got map stage job 68 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:46,867 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:46,867 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:46,868 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:46,868 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:46,879 INFO memory.MemoryStore: Block broadcast_81 stored as values in memory (estimated size 95.7 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:46,884 INFO memory.MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1456.8 MiB)\n",
      "2026-02-08 18:29:46,884 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:46,885 INFO spark.SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:46,886 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:46,886 INFO cluster.YarnScheduler: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:46,887 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 101.0 (TID 79) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:46,897 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:47,324 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 101.0 (TID 79) in 437 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:47,324 INFO scheduler.DAGScheduler: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326) finished in 0.455 s\n",
      "2026-02-08 18:29:47,324 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:47,325 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:47,325 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:47,325 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:47,324 INFO cluster.YarnScheduler: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:47,363 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:47,364 INFO scheduler.DAGScheduler: Got job 69 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:47,364 INFO scheduler.DAGScheduler: Final stage: ResultStage 103 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:47,364 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)\n",
      "2026-02-08 18:29:47,365 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:47,365 INFO scheduler.DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:47,374 INFO memory.MemoryStore: Block broadcast_82 stored as values in memory (estimated size 180.4 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:47,376 INFO memory.MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 49.5 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:47,377 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.2.196.57:46029 (size: 49.5 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:47,378 INFO spark.SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:47,379 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:47,379 INFO cluster.YarnScheduler: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:47,380 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 103.0 (TID 80) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:47,394 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on algo-1:39391 (size: 49.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:47,405 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:47,558 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 103.0 (TID 80) in 178 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:47,558 INFO cluster.YarnScheduler: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:47,559 INFO scheduler.DAGScheduler: ResultStage 103 (collect at AnalysisRunner.scala:326) finished in 0.192 s\n",
      "2026-02-08 18:29:47,559 INFO scheduler.DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:47,559 INFO cluster.YarnScheduler: Killing all running tasks in stage 103: Stage finished\n",
      "2026-02-08 18:29:47,559 INFO scheduler.DAGScheduler: Job 69 finished: collect at AnalysisRunner.scala:326, took 0.196309 s\n",
      "2026-02-08 18:29:47,740 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:47,741 INFO scheduler.DAGScheduler: Got job 70 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:47,741 INFO scheduler.DAGScheduler: Final stage: ResultStage 104 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:47,741 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:47,742 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:47,742 INFO scheduler.DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:47,748 INFO memory.MemoryStore: Block broadcast_83 stored as values in memory (estimated size 50.5 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:47,749 INFO memory.MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:47,750 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:47,754 INFO spark.SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:47,754 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:47,755 INFO cluster.YarnScheduler: Adding task set 104.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:47,757 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 104.0 (TID 81) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:47,764 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:47,942 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 104.0 (TID 81) in 185 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:47,943 INFO cluster.YarnScheduler: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:47,943 INFO scheduler.DAGScheduler: ResultStage 104 (treeReduce at KLLRunner.scala:107) finished in 0.200 s\n",
      "2026-02-08 18:29:47,944 INFO scheduler.DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:47,944 INFO cluster.YarnScheduler: Killing all running tasks in stage 104: Stage finished\n",
      "2026-02-08 18:29:47,945 INFO scheduler.DAGScheduler: Job 70 finished: treeReduce at KLLRunner.scala:107, took 0.204377 s\n",
      "2026-02-08 18:29:48,098 INFO scheduler.DAGScheduler: Registering RDD 419 (collect at AnalysisRunner.scala:326) as input to shuffle 34\n",
      "2026-02-08 18:29:48,098 INFO scheduler.DAGScheduler: Got map stage job 71 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:48,099 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:48,099 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:48,099 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:48,100 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:48,106 INFO memory.MemoryStore: Block broadcast_84 stored as values in memory (estimated size 86.4 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:48,108 INFO memory.MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:48,109 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:48,110 INFO spark.SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:48,110 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:48,111 INFO cluster.YarnScheduler: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:48,111 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 105.0 (TID 82) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:48,123 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,184 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 105.0 (TID 82) in 73 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:48,184 INFO cluster.YarnScheduler: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:48,185 INFO scheduler.DAGScheduler: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326) finished in 0.082 s\n",
      "2026-02-08 18:29:48,186 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:48,186 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:48,186 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:48,186 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:48,242 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:48,243 INFO scheduler.DAGScheduler: Got job 72 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:48,243 INFO scheduler.DAGScheduler: Final stage: ResultStage 107 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:48,243 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)\n",
      "2026-02-08 18:29:48,243 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:48,244 INFO scheduler.DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:48,245 INFO memory.MemoryStore: Block broadcast_85 stored as values in memory (estimated size 66.2 KiB, free 1456.3 MiB)\n",
      "2026-02-08 18:29:48,252 INFO memory.MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1456.3 MiB)\n",
      "2026-02-08 18:29:48,253 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.2.196.57:46029 (size: 19.1 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:48,253 INFO spark.SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:48,254 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:48,254 INFO cluster.YarnScheduler: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:48,255 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 107.0 (TID 83) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:48,265 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on algo-1:39391 (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,271 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:48,277 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 107.0 (TID 83) in 22 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:48,278 INFO cluster.YarnScheduler: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:48,278 INFO scheduler.DAGScheduler: ResultStage 107 (collect at AnalysisRunner.scala:326) finished in 0.034 s\n",
      "2026-02-08 18:29:48,279 INFO scheduler.DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:48,279 INFO cluster.YarnScheduler: Killing all running tasks in stage 107: Stage finished\n",
      "2026-02-08 18:29:48,279 INFO scheduler.DAGScheduler: Job 72 finished: collect at AnalysisRunner.scala:326, took 0.037243 s\n",
      "2026-02-08 18:29:48,375 INFO scheduler.DAGScheduler: Registering RDD 427 (collect at AnalysisRunner.scala:326) as input to shuffle 35\n",
      "2026-02-08 18:29:48,376 INFO scheduler.DAGScheduler: Got map stage job 73 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:48,377 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 108 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:48,378 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:48,378 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:48,379 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[427] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:48,384 INFO memory.MemoryStore: Block broadcast_86 stored as values in memory (estimated size 95.7 KiB, free 1456.2 MiB)\n",
      "2026-02-08 18:29:48,432 INFO memory.MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1456.1 MiB)\n",
      "2026-02-08 18:29:48,434 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.2.196.57:46029 (size: 30.3 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:48,435 INFO spark.SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:48,435 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[427] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:48,437 INFO cluster.YarnScheduler: Adding task set 108.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:48,436 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:48,438 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,439 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 108.0 (TID 84) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:48,449 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on 10.2.196.57:46029 in memory (size: 49.3 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:48,451 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on algo-1:39391 in memory (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,452 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on algo-1:39391 (size: 30.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,466 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on 10.2.196.57:46029 in memory (size: 19.1 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:48,469 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on algo-1:39391 in memory (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,477 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:48,479 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,490 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:48,491 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,497 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:48,499 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,502 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on 10.2.196.57:46029 in memory (size: 19.1 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:48,503 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on algo-1:39391 in memory (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,515 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:48,521 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,524 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:48,525 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,529 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:48,530 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,535 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on 10.2.196.57:46029 in memory (size: 49.5 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:48,536 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on algo-1:39391 in memory (size: 49.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,540 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:48,544 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,549 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on 10.2.196.57:46029 in memory (size: 19.1 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:48,551 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on algo-1:39391 in memory (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,562 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:48,564 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,568 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on 10.2.196.57:46029 in memory (size: 30.1 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:48,570 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on algo-1:39391 in memory (size: 30.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,639 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 108.0 (TID 84) in 200 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:48,640 INFO cluster.YarnScheduler: Removed TaskSet 108.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:48,640 INFO scheduler.DAGScheduler: ShuffleMapStage 108 (collect at AnalysisRunner.scala:326) finished in 0.261 s\n",
      "2026-02-08 18:29:48,641 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:48,641 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:48,641 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:48,641 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:48,674 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:48,674 INFO scheduler.DAGScheduler: Got job 74 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:48,675 INFO scheduler.DAGScheduler: Final stage: ResultStage 110 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:48,675 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)\n",
      "2026-02-08 18:29:48,675 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:48,675 INFO scheduler.DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[430] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:48,682 INFO memory.MemoryStore: Block broadcast_87 stored as values in memory (estimated size 180.4 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:48,684 INFO memory.MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:48,684 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.2.196.57:46029 (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:48,685 INFO spark.SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:48,685 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[430] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:48,685 INFO cluster.YarnScheduler: Adding task set 110.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:48,687 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 110.0 (TID 85) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:48,694 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on algo-1:39391 (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:48,708 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:48,821 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 110.0 (TID 85) in 135 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:48,822 INFO cluster.YarnScheduler: Removed TaskSet 110.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:48,822 INFO scheduler.DAGScheduler: ResultStage 110 (collect at AnalysisRunner.scala:326) finished in 0.146 s\n",
      "2026-02-08 18:29:48,823 INFO scheduler.DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:48,823 INFO cluster.YarnScheduler: Killing all running tasks in stage 110: Stage finished\n",
      "2026-02-08 18:29:48,823 INFO scheduler.DAGScheduler: Job 74 finished: collect at AnalysisRunner.scala:326, took 0.149089 s\n",
      "2026-02-08 18:29:48,912 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:48,913 INFO scheduler.DAGScheduler: Got job 75 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:48,913 INFO scheduler.DAGScheduler: Final stage: ResultStage 111 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:48,913 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:48,914 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:48,914 INFO scheduler.DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[440] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:48,918 INFO memory.MemoryStore: Block broadcast_88 stored as values in memory (estimated size 50.5 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:48,919 INFO memory.MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:48,919 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:48,920 INFO spark.SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:48,920 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[440] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:48,920 INFO cluster.YarnScheduler: Adding task set 111.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:48,922 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 111.0 (TID 86) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:48,927 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:49,040 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 111.0 (TID 86) in 118 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:49,040 INFO cluster.YarnScheduler: Removed TaskSet 111.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:49,041 INFO scheduler.DAGScheduler: ResultStage 111 (treeReduce at KLLRunner.scala:107) finished in 0.127 s\n",
      "2026-02-08 18:29:49,041 INFO scheduler.DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:49,041 INFO cluster.YarnScheduler: Killing all running tasks in stage 111: Stage finished\n",
      "2026-02-08 18:29:49,041 INFO scheduler.DAGScheduler: Job 75 finished: treeReduce at KLLRunner.scala:107, took 0.129015 s\n",
      "2026-02-08 18:29:49,166 INFO scheduler.DAGScheduler: Registering RDD 445 (collect at AnalysisRunner.scala:326) as input to shuffle 36\n",
      "2026-02-08 18:29:49,166 INFO scheduler.DAGScheduler: Got map stage job 76 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:49,166 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 112 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:49,166 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:49,166 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:49,167 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[445] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:49,170 INFO memory.MemoryStore: Block broadcast_89 stored as values in memory (estimated size 86.4 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:49,172 INFO memory.MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:49,172 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:49,173 INFO spark.SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:49,173 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[445] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:49,173 INFO cluster.YarnScheduler: Adding task set 112.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:49,176 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 112.0 (TID 87) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:49,185 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:49,210 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 112.0 (TID 87) in 35 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:49,210 INFO cluster.YarnScheduler: Removed TaskSet 112.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:49,211 INFO scheduler.DAGScheduler: ShuffleMapStage 112 (collect at AnalysisRunner.scala:326) finished in 0.043 s\n",
      "2026-02-08 18:29:49,211 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:49,211 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:49,211 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:49,212 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:49,260 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:49,261 INFO scheduler.DAGScheduler: Got job 77 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:49,262 INFO scheduler.DAGScheduler: Final stage: ResultStage 114 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:49,262 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)\n",
      "2026-02-08 18:29:49,262 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:49,263 INFO scheduler.DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[448] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:49,266 INFO memory.MemoryStore: Block broadcast_90 stored as values in memory (estimated size 66.2 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:49,268 INFO memory.MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:49,268 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.2.196.57:46029 (size: 19.1 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:49,269 INFO spark.SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:49,270 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[448] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:49,270 INFO cluster.YarnScheduler: Adding task set 114.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:49,271 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 114.0 (TID 88) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:49,285 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on algo-1:39391 (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:49,288 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:49,295 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 114.0 (TID 88) in 24 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:49,295 INFO cluster.YarnScheduler: Removed TaskSet 114.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:49,296 INFO scheduler.DAGScheduler: ResultStage 114 (collect at AnalysisRunner.scala:326) finished in 0.031 s\n",
      "2026-02-08 18:29:49,296 INFO scheduler.DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:49,296 INFO cluster.YarnScheduler: Killing all running tasks in stage 114: Stage finished\n",
      "2026-02-08 18:29:49,296 INFO scheduler.DAGScheduler: Job 77 finished: collect at AnalysisRunner.scala:326, took 0.035335 s\n",
      "2026-02-08 18:29:49,347 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:49,348 INFO scheduler.DAGScheduler: Registering RDD 456 (countByKey at ColumnProfiler.scala:592) as input to shuffle 37\n",
      "2026-02-08 18:29:49,348 INFO scheduler.DAGScheduler: Got job 78 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:49,348 INFO scheduler.DAGScheduler: Final stage: ResultStage 116 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:49,348 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)\n",
      "2026-02-08 18:29:49,349 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 115)\n",
      "2026-02-08 18:29:49,350 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[456] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:49,353 INFO memory.MemoryStore: Block broadcast_91 stored as values in memory (estimated size 42.9 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:49,355 INFO memory.MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:49,356 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:49,357 INFO spark.SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:49,357 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[456] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:49,357 INFO cluster.YarnScheduler: Adding task set 115.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:49,358 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 115.0 (TID 89) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:49,366 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:49,393 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 115.0 (TID 89) in 35 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:49,393 INFO cluster.YarnScheduler: Removed TaskSet 115.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:49,394 INFO scheduler.DAGScheduler: ShuffleMapStage 115 (countByKey at ColumnProfiler.scala:592) finished in 0.044 s\n",
      "2026-02-08 18:29:49,394 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:49,395 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:49,395 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 116)\n",
      "2026-02-08 18:29:49,395 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:49,395 INFO scheduler.DAGScheduler: Submitting ResultStage 116 (ShuffledRDD[457] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:49,397 INFO memory.MemoryStore: Block broadcast_92 stored as values in memory (estimated size 5.1 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:49,398 INFO memory.MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:49,399 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:49,399 INFO spark.SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:49,400 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (ShuffledRDD[457] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:49,400 INFO cluster.YarnScheduler: Adding task set 116.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:49,401 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 116.0 (TID 90) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:49,408 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:49,410 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:49,421 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 116.0 (TID 90) in 21 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:49,422 INFO cluster.YarnScheduler: Removed TaskSet 116.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:49,423 INFO scheduler.DAGScheduler: ResultStage 116 (countByKey at ColumnProfiler.scala:592) finished in 0.026 s\n",
      "2026-02-08 18:29:49,423 INFO scheduler.DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:49,424 INFO cluster.YarnScheduler: Killing all running tasks in stage 116: Stage finished\n",
      "2026-02-08 18:29:49,426 INFO scheduler.DAGScheduler: Job 78 finished: countByKey at ColumnProfiler.scala:592, took 0.078511 s\n",
      "2026-02-08 18:29:49,572 INFO scheduler.DAGScheduler: Registering RDD 462 (collect at AnalysisRunner.scala:326) as input to shuffle 38\n",
      "2026-02-08 18:29:49,572 INFO scheduler.DAGScheduler: Got map stage job 79 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:49,572 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 117 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:49,573 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:49,573 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:49,574 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[462] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:49,584 INFO memory.MemoryStore: Block broadcast_93 stored as values in memory (estimated size 95.7 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:49,589 INFO memory.MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:49,589 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:49,590 INFO spark.SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:49,591 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[462] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:49,591 INFO cluster.YarnScheduler: Adding task set 117.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:49,592 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 117.0 (TID 91) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:49,600 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:49,776 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 117.0 (TID 91) in 184 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:49,776 INFO cluster.YarnScheduler: Removed TaskSet 117.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:49,777 INFO scheduler.DAGScheduler: ShuffleMapStage 117 (collect at AnalysisRunner.scala:326) finished in 0.197 s\n",
      "2026-02-08 18:29:49,780 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:49,781 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:49,781 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:49,782 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:49,825 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:49,826 INFO scheduler.DAGScheduler: Got job 80 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:49,826 INFO scheduler.DAGScheduler: Final stage: ResultStage 119 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:49,826 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)\n",
      "2026-02-08 18:29:49,827 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:49,827 INFO scheduler.DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[465] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:49,838 INFO memory.MemoryStore: Block broadcast_94 stored as values in memory (estimated size 180.4 KiB, free 1456.7 MiB)\n",
      "2026-02-08 18:29:49,841 INFO memory.MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1456.7 MiB)\n",
      "2026-02-08 18:29:49,841 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on 10.2.196.57:46029 (size: 49.3 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:49,842 INFO spark.SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:49,842 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[465] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:49,843 INFO cluster.YarnScheduler: Adding task set 119.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:49,844 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 119.0 (TID 92) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:49,851 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on algo-1:39391 (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:49,867 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:49,951 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 119.0 (TID 92) in 107 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:49,952 INFO cluster.YarnScheduler: Removed TaskSet 119.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:49,953 INFO scheduler.DAGScheduler: ResultStage 119 (collect at AnalysisRunner.scala:326) finished in 0.124 s\n",
      "2026-02-08 18:29:49,958 INFO scheduler.DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:49,959 INFO cluster.YarnScheduler: Killing all running tasks in stage 119: Stage finished\n",
      "2026-02-08 18:29:49,960 INFO scheduler.DAGScheduler: Job 80 finished: collect at AnalysisRunner.scala:326, took 0.134683 s\n",
      "2026-02-08 18:29:50,071 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:50,072 INFO scheduler.DAGScheduler: Got job 81 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:50,072 INFO scheduler.DAGScheduler: Final stage: ResultStage 120 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:50,073 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:50,073 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:50,074 INFO scheduler.DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[475] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:50,079 INFO memory.MemoryStore: Block broadcast_95 stored as values in memory (estimated size 50.5 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:50,081 INFO memory.MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.6 MiB)\n",
      "2026-02-08 18:29:50,082 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:50,082 INFO spark.SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:50,083 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[475] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:50,083 INFO cluster.YarnScheduler: Adding task set 120.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:50,084 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 120.0 (TID 93) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:50,091 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:50,209 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 120.0 (TID 93) in 125 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:50,209 INFO cluster.YarnScheduler: Removed TaskSet 120.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:50,210 INFO scheduler.DAGScheduler: ResultStage 120 (treeReduce at KLLRunner.scala:107) finished in 0.135 s\n",
      "2026-02-08 18:29:50,211 INFO scheduler.DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:50,211 INFO cluster.YarnScheduler: Killing all running tasks in stage 120: Stage finished\n",
      "2026-02-08 18:29:50,211 INFO scheduler.DAGScheduler: Job 81 finished: treeReduce at KLLRunner.scala:107, took 0.139577 s\n",
      "2026-02-08 18:29:50,336 INFO scheduler.DAGScheduler: Registering RDD 480 (collect at AnalysisRunner.scala:326) as input to shuffle 39\n",
      "2026-02-08 18:29:50,336 INFO scheduler.DAGScheduler: Got map stage job 82 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:50,336 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 121 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:50,336 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:50,337 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:50,337 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[480] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:50,339 INFO memory.MemoryStore: Block broadcast_96 stored as values in memory (estimated size 86.4 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:50,340 INFO memory.MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1456.5 MiB)\n",
      "2026-02-08 18:29:50,341 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:50,341 INFO spark.SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:50,341 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[480] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:50,341 INFO cluster.YarnScheduler: Adding task set 121.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:50,342 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 121.0 (TID 94) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:50,348 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:50,377 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 121.0 (TID 94) in 35 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:50,377 INFO cluster.YarnScheduler: Removed TaskSet 121.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:50,378 INFO scheduler.DAGScheduler: ShuffleMapStage 121 (collect at AnalysisRunner.scala:326) finished in 0.040 s\n",
      "2026-02-08 18:29:50,378 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:50,378 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:50,379 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:50,379 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:50,419 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:50,420 INFO scheduler.DAGScheduler: Got job 83 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:50,420 INFO scheduler.DAGScheduler: Final stage: ResultStage 123 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:50,420 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)\n",
      "2026-02-08 18:29:50,420 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:50,421 INFO scheduler.DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[483] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:50,422 INFO memory.MemoryStore: Block broadcast_97 stored as values in memory (estimated size 66.2 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:50,423 INFO memory.MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:50,424 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on 10.2.196.57:46029 (size: 19.1 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:50,424 INFO spark.SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:50,424 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[483] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:50,424 INFO cluster.YarnScheduler: Adding task set 123.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:50,425 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 123.0 (TID 95) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:50,432 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on algo-1:39391 (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:50,436 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:50,442 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 123.0 (TID 95) in 17 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:50,442 INFO cluster.YarnScheduler: Removed TaskSet 123.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:50,442 INFO scheduler.DAGScheduler: ResultStage 123 (collect at AnalysisRunner.scala:326) finished in 0.021 s\n",
      "2026-02-08 18:29:50,442 INFO scheduler.DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:50,442 INFO cluster.YarnScheduler: Killing all running tasks in stage 123: Stage finished\n",
      "2026-02-08 18:29:50,444 INFO scheduler.DAGScheduler: Job 83 finished: collect at AnalysisRunner.scala:326, took 0.024426 s\n",
      "2026-02-08 18:29:50,505 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2026-02-08 18:29:50,505 INFO scheduler.DAGScheduler: Registering RDD 491 (countByKey at ColumnProfiler.scala:592) as input to shuffle 40\n",
      "2026-02-08 18:29:50,506 INFO scheduler.DAGScheduler: Got job 84 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2026-02-08 18:29:50,506 INFO scheduler.DAGScheduler: Final stage: ResultStage 125 (countByKey at ColumnProfiler.scala:592)\n",
      "2026-02-08 18:29:50,506 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)\n",
      "2026-02-08 18:29:50,506 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 124)\n",
      "2026-02-08 18:29:50,506 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[491] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:50,510 INFO memory.MemoryStore: Block broadcast_98 stored as values in memory (estimated size 42.9 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:50,511 INFO memory.MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:50,512 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on 10.2.196.57:46029 (size: 17.6 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:50,512 INFO spark.SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:50,513 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[491] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:50,513 INFO cluster.YarnScheduler: Adding task set 124.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:50,514 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 124.0 (TID 96) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:50,521 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on algo-1:39391 (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:50,558 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 124.0 (TID 96) in 44 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:50,558 INFO cluster.YarnScheduler: Removed TaskSet 124.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:50,559 INFO scheduler.DAGScheduler: ShuffleMapStage 124 (countByKey at ColumnProfiler.scala:592) finished in 0.052 s\n",
      "2026-02-08 18:29:50,560 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:50,560 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:50,560 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 125)\n",
      "2026-02-08 18:29:50,560 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:50,561 INFO scheduler.DAGScheduler: Submitting ResultStage 125 (ShuffledRDD[492] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2026-02-08 18:29:50,562 INFO memory.MemoryStore: Block broadcast_99 stored as values in memory (estimated size 5.1 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:50,566 INFO memory.MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:50,566 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on 10.2.196.57:46029 (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:50,566 INFO spark.SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:50,569 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (ShuffledRDD[492] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:50,569 INFO cluster.YarnScheduler: Adding task set 125.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:50,570 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 125.0 (TID 97) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:50,575 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on algo-1:39391 (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:50,578 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:50,593 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 125.0 (TID 97) in 23 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:50,593 INFO cluster.YarnScheduler: Removed TaskSet 125.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:50,594 INFO scheduler.DAGScheduler: ResultStage 125 (countByKey at ColumnProfiler.scala:592) finished in 0.033 s\n",
      "2026-02-08 18:29:50,594 INFO scheduler.DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:50,594 INFO cluster.YarnScheduler: Killing all running tasks in stage 125: Stage finished\n",
      "2026-02-08 18:29:50,597 INFO scheduler.DAGScheduler: Job 84 finished: countByKey at ColumnProfiler.scala:592, took 0.091755 s\n",
      "2026-02-08 18:29:50,678 INFO scheduler.DAGScheduler: Registering RDD 497 (collect at AnalysisRunner.scala:326) as input to shuffle 41\n",
      "2026-02-08 18:29:50,678 INFO scheduler.DAGScheduler: Got map stage job 85 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:50,679 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 126 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:50,679 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:50,680 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:50,680 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[497] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:50,684 INFO memory.MemoryStore: Block broadcast_100 stored as values in memory (estimated size 95.7 KiB, free 1456.3 MiB)\n",
      "2026-02-08 18:29:50,685 INFO memory.MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1456.2 MiB)\n",
      "2026-02-08 18:29:50,686 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on 10.2.196.57:46029 (size: 30.2 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:50,686 INFO spark.SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:50,687 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[497] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:50,687 INFO cluster.YarnScheduler: Adding task set 126.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:50,687 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 126.0 (TID 98) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:50,693 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on algo-1:39391 (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:50,811 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 126.0 (TID 98) in 124 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:50,811 INFO cluster.YarnScheduler: Removed TaskSet 126.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:50,812 INFO scheduler.DAGScheduler: ShuffleMapStage 126 (collect at AnalysisRunner.scala:326) finished in 0.131 s\n",
      "2026-02-08 18:29:50,813 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:50,813 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:50,813 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:50,813 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:50,840 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:50,841 INFO scheduler.DAGScheduler: Got job 86 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:50,842 INFO scheduler.DAGScheduler: Final stage: ResultStage 128 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:50,842 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)\n",
      "2026-02-08 18:29:50,842 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:50,842 INFO scheduler.DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[500] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:50,847 INFO memory.MemoryStore: Block broadcast_101 stored as values in memory (estimated size 180.4 KiB, free 1456.1 MiB)\n",
      "2026-02-08 18:29:50,849 INFO memory.MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 49.4 KiB, free 1456.0 MiB)\n",
      "2026-02-08 18:29:50,849 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on 10.2.196.57:46029 (size: 49.4 KiB, free: 1458.1 MiB)\n",
      "2026-02-08 18:29:50,850 INFO spark.SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:50,850 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[500] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:50,850 INFO cluster.YarnScheduler: Adding task set 128.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:50,851 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 128.0 (TID 99) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:50,861 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on algo-1:39391 (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:50,870 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:50,965 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 128.0 (TID 99) in 114 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:50,965 INFO cluster.YarnScheduler: Removed TaskSet 128.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:50,966 INFO scheduler.DAGScheduler: ResultStage 128 (collect at AnalysisRunner.scala:326) finished in 0.123 s\n",
      "2026-02-08 18:29:50,967 INFO scheduler.DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:50,967 INFO cluster.YarnScheduler: Killing all running tasks in stage 128: Stage finished\n",
      "2026-02-08 18:29:50,967 INFO scheduler.DAGScheduler: Job 86 finished: collect at AnalysisRunner.scala:326, took 0.126593 s\n",
      "2026-02-08 18:29:51,103 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:51,104 INFO scheduler.DAGScheduler: Got job 87 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:51,106 INFO scheduler.DAGScheduler: Final stage: ResultStage 129 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:51,106 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:51,107 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on 10.2.196.57:46029 in memory (size: 30.3 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:51,108 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on algo-1:39391 in memory (size: 30.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,108 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:51,109 INFO scheduler.DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[510] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:51,116 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:51,117 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,120 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:51,121 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,129 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:51,131 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,137 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on 10.2.196.57:46029 in memory (size: 19.1 KiB, free: 1458.2 MiB)\n",
      "2026-02-08 18:29:51,138 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on algo-1:39391 in memory (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,139 INFO memory.MemoryStore: Block broadcast_102 stored as values in memory (estimated size 50.5 KiB, free 1456.4 MiB)\n",
      "2026-02-08 18:29:51,140 INFO memory.MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.3 MiB)\n",
      "2026-02-08 18:29:51,143 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on 10.2.196.57:46029 in memory (size: 49.3 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:51,143 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on 10.2.196.57:46029 (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:51,144 INFO spark.SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:51,145 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on algo-1:39391 in memory (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,145 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[510] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:51,146 INFO cluster.YarnScheduler: Adding task set 129.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:51,147 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:51,148 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,149 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 129.0 (TID 100) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:51,153 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:51,154 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,157 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on 10.2.196.57:46029 in memory (size: 17.6 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:51,159 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on algo-1:39391 in memory (size: 17.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,159 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on algo-1:39391 (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,161 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on 10.2.196.57:46029 in memory (size: 30.2 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:51,162 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on algo-1:39391 in memory (size: 30.2 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,163 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on 10.2.196.57:46029 in memory (size: 19.1 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:51,165 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on algo-1:39391 in memory (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,171 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:51,172 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,175 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on 10.2.196.57:46029 in memory (size: 49.4 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:51,176 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on algo-1:39391 in memory (size: 49.4 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,179 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:51,179 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,181 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on 10.2.196.57:46029 in memory (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:51,182 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on algo-1:39391 in memory (size: 3.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,185 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on 10.2.196.57:46029 in memory (size: 49.3 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:51,185 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on algo-1:39391 in memory (size: 49.3 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,358 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 129.0 (TID 100) in 209 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:51,359 INFO cluster.YarnScheduler: Removed TaskSet 129.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:51,359 INFO scheduler.DAGScheduler: ResultStage 129 (treeReduce at KLLRunner.scala:107) finished in 0.248 s\n",
      "2026-02-08 18:29:51,359 INFO scheduler.DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:51,360 INFO cluster.YarnScheduler: Killing all running tasks in stage 129: Stage finished\n",
      "2026-02-08 18:29:51,360 INFO scheduler.DAGScheduler: Job 87 finished: treeReduce at KLLRunner.scala:107, took 0.256139 s\n",
      "2026-02-08 18:29:51,473 INFO scheduler.DAGScheduler: Registering RDD 515 (collect at AnalysisRunner.scala:326) as input to shuffle 42\n",
      "2026-02-08 18:29:51,473 INFO scheduler.DAGScheduler: Got map stage job 88 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:51,474 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 130 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:51,474 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:51,474 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:51,475 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[515] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:51,479 INFO memory.MemoryStore: Block broadcast_103 stored as values in memory (estimated size 86.4 KiB, free 1457.6 MiB)\n",
      "2026-02-08 18:29:51,481 INFO memory.MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:51,481 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on 10.2.196.57:46029 (size: 26.6 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:51,482 INFO spark.SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:51,483 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[515] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:51,483 INFO cluster.YarnScheduler: Adding task set 130.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:51,484 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 130.0 (TID 101) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:51,491 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on algo-1:39391 (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,536 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 130.0 (TID 101) in 52 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:51,536 INFO cluster.YarnScheduler: Removed TaskSet 130.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:51,537 INFO scheduler.DAGScheduler: ShuffleMapStage 130 (collect at AnalysisRunner.scala:326) finished in 0.060 s\n",
      "2026-02-08 18:29:51,538 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:51,538 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:51,539 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:51,539 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:51,577 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:51,578 INFO scheduler.DAGScheduler: Got job 89 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:51,579 INFO scheduler.DAGScheduler: Final stage: ResultStage 132 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:51,579 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)\n",
      "2026-02-08 18:29:51,579 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:51,579 INFO scheduler.DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[518] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:51,582 INFO memory.MemoryStore: Block broadcast_104 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\n",
      "2026-02-08 18:29:51,584 INFO memory.MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:51,584 INFO storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on 10.2.196.57:46029 (size: 19.1 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:51,585 INFO spark.SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:51,585 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[518] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:51,585 INFO cluster.YarnScheduler: Adding task set 132.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:51,586 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 132.0 (TID 102) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:51,594 INFO storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on algo-1:39391 (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:51,598 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:51,605 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 132.0 (TID 102) in 19 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:51,605 INFO cluster.YarnScheduler: Removed TaskSet 132.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:51,606 INFO scheduler.DAGScheduler: ResultStage 132 (collect at AnalysisRunner.scala:326) finished in 0.025 s\n",
      "2026-02-08 18:29:51,607 INFO scheduler.DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:51,607 INFO cluster.YarnScheduler: Killing all running tasks in stage 132: Stage finished\n",
      "2026-02-08 18:29:51,607 INFO scheduler.DAGScheduler: Job 89 finished: collect at AnalysisRunner.scala:326, took 0.029335 s\n",
      "2026-02-08 18:29:51,743 INFO scheduler.DAGScheduler: Registering RDD 523 (collect at AnalysisRunner.scala:326) as input to shuffle 43\n",
      "2026-02-08 18:29:51,744 INFO scheduler.DAGScheduler: Got map stage job 90 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:51,744 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 133 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:51,744 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:51,745 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:51,745 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 133 (MapPartitionsRDD[523] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:51,749 INFO memory.MemoryStore: Block broadcast_105 stored as values in memory (estimated size 75.2 KiB, free 1457.4 MiB)\n",
      "2026-02-08 18:29:51,751 INFO memory.MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 1457.3 MiB)\n",
      "2026-02-08 18:29:51,751 INFO storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on 10.2.196.57:46029 (size: 25.7 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:51,751 INFO spark.SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:51,752 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 133 (MapPartitionsRDD[523] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:51,752 INFO cluster.YarnScheduler: Adding task set 133.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:51,753 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 133.0 (TID 103) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:51,759 INFO storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on algo-1:39391 (size: 25.7 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:52,061 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 133.0 (TID 103) in 308 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:52,061 INFO cluster.YarnScheduler: Removed TaskSet 133.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:52,062 INFO scheduler.DAGScheduler: ShuffleMapStage 133 (collect at AnalysisRunner.scala:326) finished in 0.316 s\n",
      "2026-02-08 18:29:52,063 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:52,063 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:52,063 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:52,063 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:52,092 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:52,093 INFO scheduler.DAGScheduler: Got job 91 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:52,093 INFO scheduler.DAGScheduler: Final stage: ResultStage 135 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:52,093 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 134)\n",
      "2026-02-08 18:29:52,093 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:52,094 INFO scheduler.DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[526] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:52,099 INFO memory.MemoryStore: Block broadcast_106 stored as values in memory (estimated size 127.5 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:52,101 INFO memory.MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 38.1 KiB, free 1457.2 MiB)\n",
      "2026-02-08 18:29:52,102 INFO storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on 10.2.196.57:46029 (size: 38.1 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:52,102 INFO spark.SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:52,102 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[526] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:52,103 INFO cluster.YarnScheduler: Adding task set 135.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:52,104 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 135.0 (TID 104) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:52,110 INFO storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on algo-1:39391 (size: 38.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:52,119 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:52,210 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 135.0 (TID 104) in 106 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:52,210 INFO cluster.YarnScheduler: Removed TaskSet 135.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:52,211 INFO scheduler.DAGScheduler: ResultStage 135 (collect at AnalysisRunner.scala:326) finished in 0.116 s\n",
      "2026-02-08 18:29:52,211 INFO scheduler.DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:52,212 INFO cluster.YarnScheduler: Killing all running tasks in stage 135: Stage finished\n",
      "2026-02-08 18:29:52,212 INFO scheduler.DAGScheduler: Job 91 finished: collect at AnalysisRunner.scala:326, took 0.119962 s\n",
      "2026-02-08 18:29:52,231 INFO codegen.CodeGenerator: Code generated in 16.814383 ms\n",
      "2026-02-08 18:29:52,299 INFO codegen.CodeGenerator: Code generated in 22.224538 ms\n",
      "2026-02-08 18:29:52,334 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2026-02-08 18:29:52,334 INFO scheduler.DAGScheduler: Got job 92 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2026-02-08 18:29:52,335 INFO scheduler.DAGScheduler: Final stage: ResultStage 136 (treeReduce at KLLRunner.scala:107)\n",
      "2026-02-08 18:29:52,335 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:52,335 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:52,336 INFO scheduler.DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[536] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2026-02-08 18:29:52,341 INFO memory.MemoryStore: Block broadcast_107 stored as values in memory (estimated size 48.4 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:52,343 INFO memory.MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:52,343 INFO storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on 10.2.196.57:46029 (size: 19.5 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:52,344 INFO spark.SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:52,344 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[536] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:52,344 INFO cluster.YarnScheduler: Adding task set 136.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:52,346 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 136.0 (TID 105) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:52,355 INFO storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on algo-1:39391 (size: 19.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:52,573 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 136.0 (TID 105) in 227 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:52,574 INFO scheduler.DAGScheduler: ResultStage 136 (treeReduce at KLLRunner.scala:107) finished in 0.238 s\n",
      "2026-02-08 18:29:52,574 INFO scheduler.DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:52,575 INFO cluster.YarnScheduler: Removed TaskSet 136.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:52,575 INFO cluster.YarnScheduler: Killing all running tasks in stage 136: Stage finished\n",
      "2026-02-08 18:29:52,575 INFO scheduler.DAGScheduler: Job 92 finished: treeReduce at KLLRunner.scala:107, took 0.241643 s\n",
      "2026-02-08 18:29:52,701 INFO codegen.CodeGenerator: Code generated in 51.455087 ms\n",
      "2026-02-08 18:29:52,717 INFO scheduler.DAGScheduler: Registering RDD 541 (collect at AnalysisRunner.scala:326) as input to shuffle 44\n",
      "2026-02-08 18:29:52,718 INFO scheduler.DAGScheduler: Got map stage job 93 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:52,718 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 137 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:52,718 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:52,718 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:52,719 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 137 (MapPartitionsRDD[541] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:52,721 INFO memory.MemoryStore: Block broadcast_108 stored as values in memory (estimated size 65.7 KiB, free 1457.1 MiB)\n",
      "2026-02-08 18:29:52,723 INFO memory.MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:52,723 INFO storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on 10.2.196.57:46029 (size: 21.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:52,724 INFO spark.SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:52,724 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 137 (MapPartitionsRDD[541] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:52,724 INFO cluster.YarnScheduler: Adding task set 137.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:52,725 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 137.0 (TID 106) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:52,732 INFO storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on algo-1:39391 (size: 21.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:52,904 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 137.0 (TID 106) in 179 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:52,904 INFO cluster.YarnScheduler: Removed TaskSet 137.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:52,905 INFO scheduler.DAGScheduler: ShuffleMapStage 137 (collect at AnalysisRunner.scala:326) finished in 0.186 s\n",
      "2026-02-08 18:29:52,906 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:52,906 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:52,906 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:52,906 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:52,996 INFO codegen.CodeGenerator: Code generated in 69.841013 ms\n",
      "2026-02-08 18:29:53,025 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2026-02-08 18:29:53,026 INFO scheduler.DAGScheduler: Got job 94 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2026-02-08 18:29:53,026 INFO scheduler.DAGScheduler: Final stage: ResultStage 139 (collect at AnalysisRunner.scala:326)\n",
      "2026-02-08 18:29:53,026 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)\n",
      "2026-02-08 18:29:53,027 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:53,027 INFO scheduler.DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[544] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2026-02-08 18:29:53,029 INFO memory.MemoryStore: Block broadcast_109 stored as values in memory (estimated size 43.9 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:53,031 INFO memory.MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 1457.0 MiB)\n",
      "2026-02-08 18:29:53,031 INFO storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on 10.2.196.57:46029 (size: 14.0 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:53,032 INFO spark.SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:53,032 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[544] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:53,032 INFO cluster.YarnScheduler: Adding task set 139.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:53,036 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 139.0 (TID 107) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:53,042 INFO storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on algo-1:39391 (size: 14.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:53,047 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:53,131 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 139.0 (TID 107) in 95 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:53,131 INFO cluster.YarnScheduler: Removed TaskSet 139.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:53,132 INFO scheduler.DAGScheduler: ResultStage 139 (collect at AnalysisRunner.scala:326) finished in 0.103 s\n",
      "2026-02-08 18:29:53,132 INFO scheduler.DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:53,133 INFO cluster.YarnScheduler: Killing all running tasks in stage 139: Stage finished\n",
      "2026-02-08 18:29:53,133 INFO scheduler.DAGScheduler: Job 94 finished: collect at AnalysisRunner.scala:326, took 0.107280 s\n",
      "2026-02-08 18:29:53,185 INFO codegen.CodeGenerator: Code generated in 46.295923 ms\n",
      "2026-02-08 18:29:53,643 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\n",
      "2026-02-08 18:29:53,736 INFO codegen.CodeGenerator: Code generated in 26.18585 ms\n",
      "2026-02-08 18:29:53,749 INFO scheduler.DAGScheduler: Registering RDD 549 (count at StatsGenerator.scala:66) as input to shuffle 45\n",
      "2026-02-08 18:29:53,750 INFO scheduler.DAGScheduler: Got map stage job 95 (count at StatsGenerator.scala:66) with 1 output partitions\n",
      "2026-02-08 18:29:53,750 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 140 (count at StatsGenerator.scala:66)\n",
      "2026-02-08 18:29:53,750 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2026-02-08 18:29:53,750 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:53,750 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[549] at count at StatsGenerator.scala:66), which has no missing parents\n",
      "2026-02-08 18:29:53,753 INFO memory.MemoryStore: Block broadcast_110 stored as values in memory (estimated size 35.2 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:53,755 INFO memory.MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:53,755 INFO storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on 10.2.196.57:46029 (size: 13.9 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:53,756 INFO spark.SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:53,756 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[549] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:53,756 INFO cluster.YarnScheduler: Adding task set 140.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:53,757 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 140.0 (TID 108) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4938 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:53,765 INFO storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on algo-1:39391 (size: 13.9 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:53,836 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 140.0 (TID 108) in 79 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:53,836 INFO cluster.YarnScheduler: Removed TaskSet 140.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:53,837 INFO scheduler.DAGScheduler: ShuffleMapStage 140 (count at StatsGenerator.scala:66) finished in 0.086 s\n",
      "2026-02-08 18:29:53,838 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2026-02-08 18:29:53,838 INFO scheduler.DAGScheduler: running: Set()\n",
      "2026-02-08 18:29:53,838 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2026-02-08 18:29:53,838 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2026-02-08 18:29:53,861 INFO codegen.CodeGenerator: Code generated in 17.020503 ms\n",
      "2026-02-08 18:29:53,887 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\n",
      "2026-02-08 18:29:53,888 INFO scheduler.DAGScheduler: Got job 96 (count at StatsGenerator.scala:66) with 1 output partitions\n",
      "2026-02-08 18:29:53,889 INFO scheduler.DAGScheduler: Final stage: ResultStage 142 (count at StatsGenerator.scala:66)\n",
      "2026-02-08 18:29:53,889 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 141)\n",
      "2026-02-08 18:29:53,889 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2026-02-08 18:29:53,890 INFO scheduler.DAGScheduler: Submitting ResultStage 142 (MapPartitionsRDD[552] at count at StatsGenerator.scala:66), which has no missing parents\n",
      "2026-02-08 18:29:53,892 INFO memory.MemoryStore: Block broadcast_111 stored as values in memory (estimated size 11.1 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:53,893 INFO memory.MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1456.9 MiB)\n",
      "2026-02-08 18:29:53,894 INFO storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on 10.2.196.57:46029 (size: 5.5 KiB, free: 1458.3 MiB)\n",
      "2026-02-08 18:29:53,894 INFO spark.SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1513\n",
      "2026-02-08 18:29:53,895 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[552] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\n",
      "2026-02-08 18:29:53,895 INFO cluster.YarnScheduler: Adding task set 142.0 with 1 tasks resource profile 0\n",
      "2026-02-08 18:29:53,896 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 142.0 (TID 109) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2026-02-08 18:29:53,914 INFO storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on algo-1:39391 (size: 5.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:53,917 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 10.2.196.57:55566\n",
      "2026-02-08 18:29:53,941 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 142.0 (TID 109) in 44 ms on algo-1 (executor 1) (1/1)\n",
      "2026-02-08 18:29:53,941 INFO cluster.YarnScheduler: Removed TaskSet 142.0, whose tasks have all completed, from pool \n",
      "2026-02-08 18:29:53,941 INFO scheduler.DAGScheduler: ResultStage 142 (count at StatsGenerator.scala:66) finished in 0.051 s\n",
      "2026-02-08 18:29:53,943 INFO scheduler.DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2026-02-08 18:29:53,943 INFO cluster.YarnScheduler: Killing all running tasks in stage 142: Stage finished\n",
      "2026-02-08 18:29:53,943 INFO scheduler.DAGScheduler: Job 96 finished: count at StatsGenerator.scala:66, took 0.055434 s\n",
      "2026-02-08 18:29:55,479 INFO storage.BlockManagerInfo: Removed broadcast_103_piece0 on 10.2.196.57:46029 in memory (size: 26.6 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:55,481 INFO storage.BlockManagerInfo: Removed broadcast_103_piece0 on algo-1:39391 in memory (size: 26.6 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,488 INFO storage.BlockManagerInfo: Removed broadcast_111_piece0 on 10.2.196.57:46029 in memory (size: 5.5 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:55,488 INFO storage.BlockManagerInfo: Removed broadcast_111_piece0 on algo-1:39391 in memory (size: 5.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,491 INFO storage.BlockManagerInfo: Removed broadcast_109_piece0 on 10.2.196.57:46029 in memory (size: 14.0 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:55,495 INFO storage.BlockManagerInfo: Removed broadcast_109_piece0 on algo-1:39391 in memory (size: 14.0 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,497 INFO storage.BlockManagerInfo: Removed broadcast_108_piece0 on 10.2.196.57:46029 in memory (size: 21.8 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:55,499 INFO storage.BlockManagerInfo: Removed broadcast_108_piece0 on algo-1:39391 in memory (size: 21.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,506 INFO storage.BlockManagerInfo: Removed broadcast_110_piece0 on 10.2.196.57:46029 in memory (size: 13.9 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:55,507 INFO storage.BlockManagerInfo: Removed broadcast_110_piece0 on algo-1:39391 in memory (size: 13.9 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,511 INFO storage.BlockManagerInfo: Removed broadcast_106_piece0 on 10.2.196.57:46029 in memory (size: 38.1 KiB, free: 1458.4 MiB)\n",
      "2026-02-08 18:29:55,513 INFO storage.BlockManagerInfo: Removed broadcast_106_piece0 on algo-1:39391 in memory (size: 38.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,516 INFO storage.BlockManagerInfo: Removed broadcast_104_piece0 on 10.2.196.57:46029 in memory (size: 19.1 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:55,517 INFO storage.BlockManagerInfo: Removed broadcast_104_piece0 on algo-1:39391 in memory (size: 19.1 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,524 INFO storage.BlockManagerInfo: Removed broadcast_105_piece0 on 10.2.196.57:46029 in memory (size: 25.7 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:55,525 INFO storage.BlockManagerInfo: Removed broadcast_105_piece0 on algo-1:39391 in memory (size: 25.7 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,527 INFO storage.BlockManagerInfo: Removed broadcast_107_piece0 on 10.2.196.57:46029 in memory (size: 19.5 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:55,528 INFO storage.BlockManagerInfo: Removed broadcast_107_piece0 on algo-1:39391 in memory (size: 19.5 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,531 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on 10.2.196.57:46029 in memory (size: 19.8 KiB, free: 1458.5 MiB)\n",
      "2026-02-08 18:29:55,531 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on algo-1:39391 in memory (size: 19.8 KiB, free: 2.8 GiB)\n",
      "2026-02-08 18:29:55,673 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\n",
      "2026-02-08 18:29:55,701 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\n",
      "2026-02-08 18:29:55,739 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\n",
      "2026-02-08 18:29:55,741 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\n",
      "2026-02-08 18:29:55,751 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\n",
      "2026-02-08 18:29:55,788 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "2026-02-08 18:29:55,863 INFO memory.MemoryStore: MemoryStore cleared\n",
      "2026-02-08 18:29:55,877 INFO storage.BlockManager: BlockManager stopped\n",
      "2026-02-08 18:29:55,889 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\n",
      "2026-02-08 18:29:55,895 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "2026-02-08 18:29:55,958 INFO spark.SparkContext: Successfully stopped SparkContext\n",
      "2026-02-08 18:29:55,959 INFO Main: Completed: Job completed successfully with no violations.\n",
      "2026-02-08 18:29:55,959 INFO Main: Write to file /opt/ml/output/message.\n",
      "2026-02-08 18:29:56,013 INFO util.ShutdownHookManager: Shutdown hook called\n",
      "2026-02-08 18:29:56,014 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-fc255fa7-7009-45c1-965f-836a454dea29\n",
      "2026-02-08 18:29:56,039 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-cd6d6782-5e76-4e66-b043-055b4222ab76\n",
      "2026-02-08 18:29:56,311 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\n",
      "2026-02-08 18:29:56,311 - DefaultDataAnalyzer - INFO - Spark job completed.\n",
      "\n",
      "Baseline generated at: s3://nfci-forecasting-222634372778/nfci-xgboost-regression/monitoring/baseline-results/xgb-nfci-reg-2026-02-08-12-30-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> </span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span> in &lt;module&gt;:38                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span>)                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Baseline generated at:\"</span>, baseline_results_uri)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>38 <span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Constraints:\"</span>, monitor.baseline_constraints())                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Statistics:\"</span>, monitor.baseline_statistics())                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008700; text-decoration-color: #008700\">'DefaultModelMonitor'</span> object has no attribute <span style=\"color: #008700; text-decoration-color: #008700\">'baseline_constraints'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m\u001b[0m\u001b[38;2;255;0;0m\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m\u001b[0m\u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m in <module>:38                                                                                   \u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m                                                                                                  \u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m   \u001b[2m35 \u001b[0m)                                                                                           \u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m   \u001b[2m36 \u001b[0m                                                                                            \u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m   \u001b[2m37 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mBaseline generated at:\u001b[0m\u001b[33m\"\u001b[0m, baseline_results_uri)                                       \u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m \u001b[31m \u001b[0m38 \u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mConstraints:\u001b[0m\u001b[33m\"\u001b[0m, monitor.baseline_constraints())                                       \u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m   \u001b[2m39 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mStatistics:\u001b[0m\u001b[33m\"\u001b[0m, monitor.baseline_statistics())                                         \u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m   \u001b[2m40 \u001b[0m                                                                                            \u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[38;2;255;0;0m\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[38;2;0;135;0m'DefaultModelMonitor'\u001b[0m object has no attribute \u001b[38;2;0;135;0m'baseline_constraints'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create baseline for Model Monitor (Data Quality / Drift)\n",
    "\n",
    "# Baseline should match captured INPUT format.\n",
    "# Used the same CSV you upload for training inference format (features only).\n",
    "# We'll create a baseline CSV from training parquet (features only).\n",
    "\n",
    "train_parquet_s3 = f\"s3://{bucket}/{S3_PREFIX['train']}/features.parquet\"\n",
    "df_train = pd.read_parquet(train_parquet_s3)\n",
    "df_train = df_train.drop(columns=[\"date\", \"Datetime\"], errors=\"ignore\")\n",
    "\n",
    "X_train = df_train.drop(columns=[TARGET_COLUMN], errors=\"ignore\")\n",
    "\n",
    "baseline_local = \"baseline.csv\"\n",
    "X_train.to_csv(baseline_local, index=False, header=False)\n",
    "\n",
    "baseline_s3_uri = sm_sess.upload_data(baseline_local, key_prefix=f\"{training_prefix}/monitoring/baseline\")\n",
    "print(\"Baseline dataset uploaded:\", baseline_s3_uri)\n",
    "\n",
    "monitor = DefaultModelMonitor(\n",
    "    role=ROLE_ARN,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    sagemaker_session=sm_sess,\n",
    ")\n",
    "\n",
    "baseline_results_uri = f\"s3://{bucket}/{training_prefix}/monitoring/baseline-results/{job_name}\"\n",
    "\n",
    "monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_s3_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True,\n",
    ")\n",
    "\n",
    "print(\"Baseline generated at:\", baseline_results_uri)\n",
    "print(\"Constraints:\", monitor.baseline_constraints())\n",
    "print(\"Statistics:\", monitor.baseline_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc58255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraints: s3://nfci-forecasting-222634372778/nfci-xgboost-regression/monitoring/baseline-results/xgb-nfci-reg-2026-02-08-12-30-10/constraints.json\n",
      "statistics : s3://nfci-forecasting-222634372778/nfci-xgboost-regression/monitoring/baseline-results/xgb-nfci-reg-2026-02-08-12-30-10/statistics.json\n"
     ]
    }
   ],
   "source": [
    "constraints_s3_uri = f\"{baseline_results_uri}/constraints.json\"\n",
    "statistics_s3_uri  = f\"{baseline_results_uri}/statistics.json\"\n",
    "\n",
    "print(\"constraints:\", constraints_s3_uri)\n",
    "print(\"statistics :\", statistics_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f7150",
   "metadata": {},
   "source": [
    "### Compare Actual vs Predicted Values (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97dbb9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_prod shape: (2400, 78) y_true shape: (2400,)\n"
     ]
    }
   ],
   "source": [
    "# compare predictions versus actuals\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 1) clean production df like training\n",
    "prod = production_df.drop(columns=[\"date\", \"Datetime\"], errors=\"ignore\").copy()\n",
    "\n",
    "# 2) y_true (ground truth)\n",
    "y_true_prod = prod[TARGET_COLUMN].values\n",
    "\n",
    "# 3) X features only\n",
    "X_prod = prod.drop(columns=[TARGET_COLUMN], errors=\"ignore\")\n",
    "\n",
    "print(\"X_prod shape:\", X_prod.shape, \"y_true shape:\", y_true_prod.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c867e4",
   "metadata": {},
   "source": [
    "### predicted Vs Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d389fb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.61879</td>\n",
       "      <td>-0.561555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.29288</td>\n",
       "      <td>-0.576910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28082</td>\n",
       "      <td>-0.213693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16847</td>\n",
       "      <td>-0.102921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.26647</td>\n",
       "      <td>-0.126143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Predicted\n",
       "0 -0.61879  -0.561555\n",
       "1 -0.29288  -0.576910\n",
       "2  0.28082  -0.213693\n",
       "3  0.16847  -0.102921\n",
       "4 -0.26647  -0.126143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "prod_small = production_df.drop(columns=[\"date\", \"Datetime\"], errors=\"ignore\").copy()\n",
    "\n",
    "y_actual = prod_small[TARGET_COLUMN].values[:5]\n",
    "X_small = prod_small.drop(columns=[TARGET_COLUMN]).iloc[:5]\n",
    "\n",
    "preds = []\n",
    "for i in range(5):\n",
    "    row = X_small.iloc[i].tolist()\n",
    "    pred_text = predictor.predict(row)  # string JSON\n",
    "    \n",
    "    pred_obj = json.loads(pred_text)\n",
    "    score = pred_obj[\"predictions\"][0][\"score\"]\n",
    "    preds.append(float(score))\n",
    "\n",
    "y_pred = np.array(preds)\n",
    "\n",
    "pd.DataFrame({\"Actual\": y_actual, \"Predicted\": y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfcd3a5",
   "metadata": {},
   "source": [
    "#### Verify Captured Inference Logs in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "887ea8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Captured data files:\n",
      "  nfci-xgboost-regression/data-capture/nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10/nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10/AllTraffic/2026/02/08/12/52-13-957-834adfa3-f283-4eec-9836-2ace7f5de07f.jsonl (5857 bytes)\n",
      "  nfci-xgboost-regression/data-capture/nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10/nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10/AllTraffic/2026/02/08/13/12-03-855-13ef6c0f-a8bf-4d88-8b43-64e406e50335.jsonl (6876 bytes)\n",
      "  nfci-xgboost-regression/data-capture/nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10/nfci-xgb-endpoint-xgb-nfci-reg-2026-02-08-12-30-10/AllTraffic/2026/02/08/18/23-00-494-0a02aad4-3c35-43ca-882e-9dd58a57b254.jsonl (5857 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Check captured data\n",
    "response = s3_client.list_objects_v2(\n",
    "    Bucket=BUCKET_NAME,\n",
    "    Prefix=data_capture_prefix,\n",
    "    MaxKeys=10\n",
    ")\n",
    "\n",
    "print(f\"\\nCaptured data files:\")\n",
    "for obj in response.get('Contents', []):\n",
    "    print(f\"  {obj['Key']} ({obj['Size']} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535006ea",
   "metadata": {},
   "source": [
    "### Define Custom CloudWatch Metric Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ed13edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Monitor instance created\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "# Create Model Monitor instance\n",
    "monitor = DefaultModelMonitor(\n",
    "    role=ROLE_ARN,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "print(\"Model Monitor instance created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b2deb",
   "metadata": {},
   "source": [
    "### Compute Production Metrics (RMSE & MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51b04654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built-in SageMaker Endpoint Metrics:\n",
      "  AWS/SageMaker: Invocations\n",
      "  AWS/SageMaker: InvocationsPerInstance\n",
      "  AWS/SageMaker: ModelLatency\n",
      "  AWS/SageMaker: OverheadLatency\n",
      "  AWS/SageMaker: Invocation4XXErrors\n",
      "  AWS/SageMaker: Invocation5XXErrors\n"
     ]
    }
   ],
   "source": [
    "# Check built-in SageMaker endpoint metrics\n",
    "print(\"Built-in SageMaker Endpoint Metrics:\")\n",
    "\n",
    "metrics_to_check = [\n",
    "    'Invocations',\n",
    "    'InvocationsPerInstance', \n",
    "    'ModelLatency',\n",
    "    'OverheadLatency',\n",
    "    'Invocation4XXErrors',\n",
    "    'Invocation5XXErrors',\n",
    "]\n",
    "\n",
    "for metric_name in metrics_to_check:\n",
    "    print(f\"  AWS/SageMaker: {metric_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f5e54",
   "metadata": {},
   "source": [
    "### Publish Row-Level Metrics to CloudWatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cd90d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom metric function defined\n"
     ]
    }
   ],
   "source": [
    "# Publish custom metrics for NFCI forecasting\n",
    "def publish_forecast_metrics(forecast_mean, actual_value=None):\n",
    "    \"\"\"\n",
    "    Publish custom CloudWatch metrics for NFCI forecasting.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.utcnow()\n",
    "    \n",
    "    metrics = [\n",
    "        {\n",
    "            'MetricName': 'ForecastMean',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'Model', 'Value': 'DeepAR'},\n",
    "            ],\n",
    "            'Timestamp': timestamp,\n",
    "            'Value': float(forecast_mean[0]),  # First month forecast\n",
    "            'Unit': 'None'\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # If actuals exists, compute and publish error\n",
    "    if actual_value is not None:\n",
    "        error = abs(forecast_mean[0] - actual_value)\n",
    "        metrics.append({\n",
    "            'MetricName': 'ForecastError',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'Model', 'Value': 'DeepAR'},\n",
    "            ],\n",
    "            'Timestamp': timestamp,\n",
    "            'Value': error,\n",
    "            'Unit': 'None'\n",
    "        })\n",
    "    \n",
    "    cw_client.put_metric_data(\n",
    "        Namespace='NFCI-Forecasting',\n",
    "        MetricData=metrics\n",
    "    )\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Custom metric function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6dee9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker\", region_name=AWS_REGION)\n",
    "s3_client = boto3.client(\"s3\", region_name=AWS_REGION)\n",
    "cw_client = boto3.client(\"cloudwatch\", region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9401d8",
   "metadata": {},
   "source": [
    "### Publish Summary Production Metrics to CloudWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d32c4686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing production metrics to CloudWatch...\n",
      "\n",
      "RMSE: 0.2904604507216057\n",
      "MAE : 0.2494990851368904\n",
      "\n",
      "Publishing production metrics to CloudWatch...\n",
      "\n",
      "Row 1: Predicted=-0.5616, Actual=-0.6188, Error=0.0572\n",
      "Row 2: Predicted=-0.5769, Actual=-0.2929, Error=0.2840\n",
      "Row 3: Predicted=-0.2137, Actual=0.2808, Error=0.4945\n",
      "Row 4: Predicted=-0.1029, Actual=0.1685, Error=0.2714\n",
      "Row 5: Predicted=-0.1261, Actual=-0.2665, Error=0.1403\n",
      "\n",
      "Published ProductionRMSE=0.2905, ProductionMAE=0.2495\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Send predictions and publish metrics with actual values\n",
    "print(\"Publishing production metrics to CloudWatch...\\n\")\n",
    "\n",
    "# Use the predictions and actuals we already computed\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
    "mae = mean_absolute_error(y_actual, y_pred)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "\n",
    "print(\"\\nPublishing production metrics to CloudWatch...\\n\")\n",
    "\n",
    "for i in range(len(y_actual)):\n",
    "    metrics = publish_forecast_metrics(\n",
    "        forecast_mean=[y_pred[i]],\n",
    "        actual_value=y_actual[i]\n",
    "    )\n",
    "\n",
    "    error = abs(y_pred[i] - y_actual[i])\n",
    "    print(f\"Row {i+1}: Predicted={y_pred[i]:.4f}, Actual={y_actual[i]:.4f}, Error={error:.4f}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "# Also publish summary metrics\n",
    "cw_client.put_metric_data(\n",
    "    Namespace='NFCI-Forecasting',\n",
    "    MetricData=[\n",
    "        {\n",
    "            'MetricName': 'ProductionRMSE',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'Model', 'Value': 'DeepAR'},\n",
    "            ],\n",
    "            'Value': rmse,\n",
    "            'Unit': 'None'\n",
    "        },\n",
    "        {\n",
    "            'MetricName': 'ProductionMAE',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'Model', 'Value': 'DeepAR'},\n",
    "            ],\n",
    "            'Value': mae,\n",
    "            'Unit': 'None'\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"\\nPublished ProductionRMSE={rmse:.4f}, ProductionMAE={mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
